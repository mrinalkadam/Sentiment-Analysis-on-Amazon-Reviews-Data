{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mrinalkadam/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/mrinalkadam/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/mrinalkadam/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# import required libraries and methods from them\n",
    "\n",
    "from platform import python_version\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "import re\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import contractions\n",
    "\n",
    "import gensim\n",
    "import gensim.downloader as api\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset,DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.8.5'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the python version being used by the jupyter notebook\n",
    "\n",
    "python_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marketplace</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_category</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>vine</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>37000337</td>\n",
       "      <td>R3DT59XH7HXR9K</td>\n",
       "      <td>B00303FI0G</td>\n",
       "      <td>529320574</td>\n",
       "      <td>Arthur Court Paper Towel Holder</td>\n",
       "      <td>Kitchen</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Beautiful. Looks great on counter</td>\n",
       "      <td>Beautiful.  Looks great on counter.</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>15272914</td>\n",
       "      <td>R1LFS11BNASSU8</td>\n",
       "      <td>B00JCZKZN6</td>\n",
       "      <td>274237558</td>\n",
       "      <td>Olde Thompson Bavaria Glass Salt and Pepper Mi...</td>\n",
       "      <td>Kitchen</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Awesome &amp; Self-ness</td>\n",
       "      <td>I personally have 5 days sets and have also bo...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>36137863</td>\n",
       "      <td>R296RT05AG0AF6</td>\n",
       "      <td>B00JLIKA5C</td>\n",
       "      <td>544675303</td>\n",
       "      <td>Progressive International PL8 Professional Man...</td>\n",
       "      <td>Kitchen</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Fabulous and worth every penny</td>\n",
       "      <td>Fabulous and worth every penny. Used for clean...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>43311049</td>\n",
       "      <td>R3V37XDZ7ZCI3L</td>\n",
       "      <td>B000GBNB8G</td>\n",
       "      <td>491599489</td>\n",
       "      <td>Zyliss Jumbo Garlic Press</td>\n",
       "      <td>Kitchen</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>A must if you love garlic on tomato marinara s...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>13763148</td>\n",
       "      <td>R14GU232NQFYX2</td>\n",
       "      <td>B00VJ5KX9S</td>\n",
       "      <td>353790155</td>\n",
       "      <td>1 X Premier Pizza Cutter - Stainless Steel 14\"...</td>\n",
       "      <td>Kitchen</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Better than sex</td>\n",
       "      <td>Worth every penny! Buy one now and be a pizza ...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4880461</th>\n",
       "      <td>US</td>\n",
       "      <td>51094108</td>\n",
       "      <td>R22DLC2P26MUMR</td>\n",
       "      <td>B00004SBGS</td>\n",
       "      <td>732420532</td>\n",
       "      <td>Le Creuset Enameled Cast-Iron 6-3/4-Quart Oval...</td>\n",
       "      <td>Kitchen</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>41</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Not as sturdy as you'd think.</td>\n",
       "      <td>After a month of heavy use, primarily as a chi...</td>\n",
       "      <td>2000-04-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4880462</th>\n",
       "      <td>US</td>\n",
       "      <td>50562512</td>\n",
       "      <td>R1N6KLTENLQOMT</td>\n",
       "      <td>B00004SBIA</td>\n",
       "      <td>261705371</td>\n",
       "      <td>Le Creuset Enameled Cast-Iron 2-Quart Heart Ca...</td>\n",
       "      <td>Kitchen</td>\n",
       "      <td>5</td>\n",
       "      <td>84</td>\n",
       "      <td>92</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>A Sweetheart of A Pan</td>\n",
       "      <td>I've used my Le Creuset enameled cast iron coo...</td>\n",
       "      <td>2000-04-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4880463</th>\n",
       "      <td>US</td>\n",
       "      <td>52469742</td>\n",
       "      <td>R10TW4QXDV8KJC</td>\n",
       "      <td>B00004SPEF</td>\n",
       "      <td>191184892</td>\n",
       "      <td>Krups 358-70 La Glaciere Ice Cream Maker</td>\n",
       "      <td>Kitchen</td>\n",
       "      <td>4</td>\n",
       "      <td>55</td>\n",
       "      <td>60</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Ice Cream Like a Dream</td>\n",
       "      <td>According to my wife, this is \\\\\"the best birt...</td>\n",
       "      <td>2000-04-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4880464</th>\n",
       "      <td>US</td>\n",
       "      <td>51865238</td>\n",
       "      <td>R41RL2U1FSQ4V</td>\n",
       "      <td>B00004RHR6</td>\n",
       "      <td>912491903</td>\n",
       "      <td>Hoffritz Stainless-Steel Manual Can Opener</td>\n",
       "      <td>Kitchen</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>42</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Opens anything and everything</td>\n",
       "      <td>Hoffritz has a name of producing a trendy and ...</td>\n",
       "      <td>2000-04-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4880465</th>\n",
       "      <td>US</td>\n",
       "      <td>52900320</td>\n",
       "      <td>R1NHMPKSJG2E37</td>\n",
       "      <td>B0000021VO</td>\n",
       "      <td>41913389</td>\n",
       "      <td>Tammy Rogers</td>\n",
       "      <td>Kitchen</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>The more you listen, the more you hear...</td>\n",
       "      <td>OK. I was late to snap to the Dead Reckoners. ...</td>\n",
       "      <td>2000-01-20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4880466 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        marketplace  customer_id       review_id  product_id  product_parent  \\\n",
       "0                US     37000337  R3DT59XH7HXR9K  B00303FI0G       529320574   \n",
       "1                US     15272914  R1LFS11BNASSU8  B00JCZKZN6       274237558   \n",
       "2                US     36137863  R296RT05AG0AF6  B00JLIKA5C       544675303   \n",
       "3                US     43311049  R3V37XDZ7ZCI3L  B000GBNB8G       491599489   \n",
       "4                US     13763148  R14GU232NQFYX2  B00VJ5KX9S       353790155   \n",
       "...             ...          ...             ...         ...             ...   \n",
       "4880461          US     51094108  R22DLC2P26MUMR  B00004SBGS       732420532   \n",
       "4880462          US     50562512  R1N6KLTENLQOMT  B00004SBIA       261705371   \n",
       "4880463          US     52469742  R10TW4QXDV8KJC  B00004SPEF       191184892   \n",
       "4880464          US     51865238   R41RL2U1FSQ4V  B00004RHR6       912491903   \n",
       "4880465          US     52900320  R1NHMPKSJG2E37  B0000021VO        41913389   \n",
       "\n",
       "                                             product_title product_category  \\\n",
       "0                          Arthur Court Paper Towel Holder          Kitchen   \n",
       "1        Olde Thompson Bavaria Glass Salt and Pepper Mi...          Kitchen   \n",
       "2        Progressive International PL8 Professional Man...          Kitchen   \n",
       "3                                Zyliss Jumbo Garlic Press          Kitchen   \n",
       "4        1 X Premier Pizza Cutter - Stainless Steel 14\"...          Kitchen   \n",
       "...                                                    ...              ...   \n",
       "4880461  Le Creuset Enameled Cast-Iron 6-3/4-Quart Oval...          Kitchen   \n",
       "4880462  Le Creuset Enameled Cast-Iron 2-Quart Heart Ca...          Kitchen   \n",
       "4880463           Krups 358-70 La Glaciere Ice Cream Maker          Kitchen   \n",
       "4880464         Hoffritz Stainless-Steel Manual Can Opener          Kitchen   \n",
       "4880465                                       Tammy Rogers          Kitchen   \n",
       "\n",
       "         star_rating  helpful_votes  total_votes vine verified_purchase  \\\n",
       "0                  5              0            0    N                 Y   \n",
       "1                  5              0            1    N                 Y   \n",
       "2                  5              0            0    N                 Y   \n",
       "3                  5              0            1    N                 Y   \n",
       "4                  5              0            0    N                 Y   \n",
       "...              ...            ...          ...  ...               ...   \n",
       "4880461            4             30           41    N                 N   \n",
       "4880462            5             84           92    N                 N   \n",
       "4880463            4             55           60    N                 N   \n",
       "4880464            4             30           42    N                 N   \n",
       "4880465            5              5            5    N                 N   \n",
       "\n",
       "                                   review_headline  \\\n",
       "0                Beautiful. Looks great on counter   \n",
       "1                              Awesome & Self-ness   \n",
       "2                   Fabulous and worth every penny   \n",
       "3                                       Five Stars   \n",
       "4                                  Better than sex   \n",
       "...                                            ...   \n",
       "4880461              Not as sturdy as you'd think.   \n",
       "4880462                      A Sweetheart of A Pan   \n",
       "4880463                     Ice Cream Like a Dream   \n",
       "4880464              Opens anything and everything   \n",
       "4880465  The more you listen, the more you hear...   \n",
       "\n",
       "                                               review_body review_date  \n",
       "0                      Beautiful.  Looks great on counter.  2015-08-31  \n",
       "1        I personally have 5 days sets and have also bo...  2015-08-31  \n",
       "2        Fabulous and worth every penny. Used for clean...  2015-08-31  \n",
       "3        A must if you love garlic on tomato marinara s...  2015-08-31  \n",
       "4        Worth every penny! Buy one now and be a pizza ...  2015-08-31  \n",
       "...                                                    ...         ...  \n",
       "4880461  After a month of heavy use, primarily as a chi...  2000-04-28  \n",
       "4880462  I've used my Le Creuset enameled cast iron coo...  2000-04-28  \n",
       "4880463  According to my wife, this is \\\\\"the best birt...  2000-04-28  \n",
       "4880464  Hoffritz has a name of producing a trendy and ...  2000-04-24  \n",
       "4880465  OK. I was late to snap to the Dead Reckoners. ...  2000-01-20  \n",
       "\n",
       "[4880466 rows x 15 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the input dataset into a dataframe\n",
    "\n",
    "df = pd.read_csv(\"data.tsv\", sep='\\t', quoting=3)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Dataset Generation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "      <th>star_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beautiful.  Looks great on counter.</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I personally have 5 days sets and have also bo...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fabulous and worth every penny. Used for clean...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A must if you love garlic on tomato marinara s...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Worth every penny! Buy one now and be a pizza ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4880461</th>\n",
       "      <td>After a month of heavy use, primarily as a chi...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4880462</th>\n",
       "      <td>I've used my Le Creuset enameled cast iron coo...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4880463</th>\n",
       "      <td>According to my wife, this is \\\\\"the best birt...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4880464</th>\n",
       "      <td>Hoffritz has a name of producing a trendy and ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4880465</th>\n",
       "      <td>OK. I was late to snap to the Dead Reckoners. ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4880466 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               review_body  star_rating\n",
       "0                      Beautiful.  Looks great on counter.            5\n",
       "1        I personally have 5 days sets and have also bo...            5\n",
       "2        Fabulous and worth every penny. Used for clean...            5\n",
       "3        A must if you love garlic on tomato marinara s...            5\n",
       "4        Worth every penny! Buy one now and be a pizza ...            5\n",
       "...                                                    ...          ...\n",
       "4880461  After a month of heavy use, primarily as a chi...            4\n",
       "4880462  I've used my Le Creuset enameled cast iron coo...            5\n",
       "4880463  According to my wife, this is \\\\\"the best birt...            4\n",
       "4880464  Hoffritz has a name of producing a trendy and ...            4\n",
       "4880465  OK. I was late to snap to the Dead Reckoners. ...            5\n",
       "\n",
       "[4880466 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep only reviews and ratings columns\n",
    "\n",
    "df = df[[\"review_body\",\"star_rating\"]]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    3128564\n",
       "4     732471\n",
       "1     427306\n",
       "3     349929\n",
       "2     242196\n",
       "Name: star_rating, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find out the number of reviews falling under each distinct rating \n",
    "\n",
    "df['star_rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "243"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for null values in the reviews column\n",
    "\n",
    "df['review_body'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for null values in the ratings column\n",
    "\n",
    "df['star_rating'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-ba0c96652bb5>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.dropna(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# drop null value records from the dataframe\n",
    "\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "      <th>star_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Not pleased with the &amp;#34;threads&amp;#34; it crea...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fills one  16.9 ounce water bottle with two tr...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We got a similar waffle iron from Betty Crocke...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I have Lock N Locks and I hate keeping up with...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I bought this at the beginning of 9/13 even th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249995</th>\n",
       "      <td>As with all coffee 'grinders' that are actuall...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249996</th>\n",
       "      <td>Love the design of this shaker and have ordere...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249997</th>\n",
       "      <td>This mold is made of plastic and is a bit flim...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249998</th>\n",
       "      <td>I really love this yogurt maker. I made very t...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249999</th>\n",
       "      <td>Don't waste your money</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review_body  star_rating\n",
       "0       Not pleased with the &#34;threads&#34; it crea...            2\n",
       "1       fills one  16.9 ounce water bottle with two tr...            4\n",
       "2       We got a similar waffle iron from Betty Crocke...            3\n",
       "3       I have Lock N Locks and I hate keeping up with...            2\n",
       "4       I bought this at the beginning of 9/13 even th...            1\n",
       "...                                                   ...          ...\n",
       "249995  As with all coffee 'grinders' that are actuall...            2\n",
       "249996  Love the design of this shaker and have ordere...            2\n",
       "249997  This mold is made of plastic and is a bit flim...            4\n",
       "249998  I really love this yogurt maker. I made very t...            5\n",
       "249999                             Don't waste your money            1\n",
       "\n",
       "[250000 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find out records with star ratings 1,2,3,4 and 5 and select 50000 records randomly per each rating score\n",
    "\n",
    "df_1 = df[df['star_rating']==1].sample(n=50000, random_state=100)\n",
    "df_2 = df[df['star_rating']==2].sample(n=50000, random_state=100)\n",
    "df_3 = df[df['star_rating']==3].sample(n=50000, random_state=100)\n",
    "df_4 = df[df['star_rating']==4].sample(n=50000, random_state=100)\n",
    "df_5 = df[df['star_rating']==5].sample(n=50000, random_state=100)\n",
    "\n",
    "# concat the above records together to get a sample of 250000 reviews\n",
    "\n",
    "df = pd.concat([df_1,df_2,df_3,df_4,df_5]).reset_index()\n",
    "\n",
    "# shuffle the dataset\n",
    "\n",
    "df = df.sample(frac=1).reset_index()\n",
    "df.drop(['index','level_0'],axis=1,inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive, Negative, Neutral Reviews Count:\n",
      "100000 , 100000 , 50000\n"
     ]
    }
   ],
   "source": [
    "# find out the number of reviews falling under distinct ratings now\n",
    "\n",
    "print(\"Positive, Negative, Neutral Reviews Count:\")\n",
    "print(df[((df['star_rating']==4.0) | (df['star_rating']==5.0))]['star_rating'].count(),\",\",df[((df['star_rating']==1.0) | (df['star_rating']==2.0))]['star_rating'].count(),\",\",df[df['star_rating']==3.0]['star_rating'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Not pleased with the &amp;#34;threads&amp;#34; it crea...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fills one  16.9 ounce water bottle with two tr...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We got a similar waffle iron from Betty Crocke...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I have Lock N Locks and I hate keeping up with...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I bought this at the beginning of 9/13 even th...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249995</th>\n",
       "      <td>As with all coffee 'grinders' that are actuall...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249996</th>\n",
       "      <td>Love the design of this shaker and have ordere...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249997</th>\n",
       "      <td>This mold is made of plastic and is a bit flim...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249998</th>\n",
       "      <td>I really love this yogurt maker. I made very t...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249999</th>\n",
       "      <td>Don't waste your money</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review_body  star_rating  class\n",
       "0       Not pleased with the &#34;threads&#34; it crea...            2      2\n",
       "1       fills one  16.9 ounce water bottle with two tr...            4      1\n",
       "2       We got a similar waffle iron from Betty Crocke...            3      3\n",
       "3       I have Lock N Locks and I hate keeping up with...            2      2\n",
       "4       I bought this at the beginning of 9/13 even th...            1      2\n",
       "...                                                   ...          ...    ...\n",
       "249995  As with all coffee 'grinders' that are actuall...            2      2\n",
       "249996  Love the design of this shaker and have ordere...            2      2\n",
       "249997  This mold is made of plastic and is a bit flim...            4      1\n",
       "249998  I really love this yogurt maker. I made very t...            5      1\n",
       "249999                             Don't waste your money            1      2\n",
       "\n",
       "[250000 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label reviews falling under ratings 4 and 5 as 1(positive class), under ratings 1 and 2 as 2(negative class), and under rating 3 as 3(neutral class)\n",
    "\n",
    "df['class'] = np.where(((df['star_rating']==4) | (df['star_rating']==5)),1,0)\n",
    "df['class'] = np.where(((df['star_rating']==1) | (df['star_rating']==2)),2,df['class'])\n",
    "df['class'] = np.where((df['star_rating']==3),3,df['class'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Not pleased with the &amp;#34;threads&amp;#34; it crea...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fills one  16.9 ounce water bottle with two tr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We got a similar waffle iron from Betty Crocke...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I have Lock N Locks and I hate keeping up with...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I bought this at the beginning of 9/13 even th...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249995</th>\n",
       "      <td>As with all coffee 'grinders' that are actuall...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249996</th>\n",
       "      <td>Love the design of this shaker and have ordere...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249997</th>\n",
       "      <td>This mold is made of plastic and is a bit flim...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249998</th>\n",
       "      <td>I really love this yogurt maker. I made very t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249999</th>\n",
       "      <td>Don't waste your money</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review_body  class\n",
       "0       Not pleased with the &#34;threads&#34; it crea...      2\n",
       "1       fills one  16.9 ounce water bottle with two tr...      1\n",
       "2       We got a similar waffle iron from Betty Crocke...      3\n",
       "3       I have Lock N Locks and I hate keeping up with...      2\n",
       "4       I bought this at the beginning of 9/13 even th...      2\n",
       "...                                                   ...    ...\n",
       "249995  As with all coffee 'grinders' that are actuall...      2\n",
       "249996  Love the design of this shaker and have ordere...      2\n",
       "249997  This mold is made of plastic and is a bit flim...      1\n",
       "249998  I really love this yogurt maker. I made very t...      1\n",
       "249999                             Don't waste your money      2\n",
       "\n",
       "[250000 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop the rating column once you have the label('class') column\n",
    "\n",
    "df.drop(['star_rating'],axis=1,inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Not pleased with the &amp;#34;threads&amp;#34; it crea...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fills one  16.9 ounce water bottle with two tr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We got a similar waffle iron from Betty Crocke...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I have Lock N Locks and I hate keeping up with...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I bought this at the beginning of 9/13 even th...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249995</th>\n",
       "      <td>As with all coffee 'grinders' that are actuall...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249996</th>\n",
       "      <td>Love the design of this shaker and have ordere...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249997</th>\n",
       "      <td>This mold is made of plastic and is a bit flim...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249998</th>\n",
       "      <td>I really love this yogurt maker. I made very t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249999</th>\n",
       "      <td>Don't waste your money</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review_body  class\n",
       "0       Not pleased with the &#34;threads&#34; it crea...      2\n",
       "1       fills one  16.9 ounce water bottle with two tr...      1\n",
       "2       We got a similar waffle iron from Betty Crocke...      3\n",
       "3       I have Lock N Locks and I hate keeping up with...      2\n",
       "4       I bought this at the beginning of 9/13 even th...      2\n",
       "...                                                   ...    ...\n",
       "249995  As with all coffee 'grinders' that are actuall...      2\n",
       "249996  Love the design of this shaker and have ordere...      2\n",
       "249997  This mold is made of plastic and is a bit flim...      1\n",
       "249998  I really love this yogurt maker. I made very t...      1\n",
       "249999                             Don't waste your money      2\n",
       "\n",
       "[250000 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a copy of the original data frame(without any data cleaning)\n",
    "\n",
    "df_uncleaned = df.copy(deep = True)\n",
    "df_uncleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the google news word2vec model \n",
    "\n",
    "wv = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Queen', 0.4929388165473938)]\n",
      "\n",
      "\n",
      "Semantic(Cosine) similarity between the two vectors is: 0.44240144\n"
     ]
    }
   ],
   "source": [
    "# find out the vectors for different words using the above model\n",
    "\n",
    "vec_King = wv['King']\n",
    "vec_Man = wv['Man']\n",
    "vec_Woman = wv['Woman']\n",
    "vec_Queen = wv['Queen']\n",
    "\n",
    "vec_1 = vec_King-vec_Man+vec_Woman\n",
    "vec_2 = vec_Queen\n",
    "\n",
    "# find out the similarity of the vectors using 'most_similar' function\n",
    "\n",
    "print(wv.most_similar(positive=['King','Woman'], negative=['Man'], topn=1))\n",
    "print('\\n')\n",
    "\n",
    "# find out the similarity of the vectors using cosine similarity \n",
    "\n",
    "cosine_similarity = np.dot(vec_1,vec_2)/(np.linalg.norm(vec_1)* np.linalg.norm(vec_2))\n",
    "print(\"Semantic(Cosine) similarity between the two vectors is:\",cosine_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'excellent'\t'outstanding'\t0.56\n"
     ]
    }
   ],
   "source": [
    "# find out the similarity of the words\n",
    "\n",
    "print('%r\\t%r\\t%.2f' % (w1, w2, wv.similarity('excellent', 'outstanding')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### REMOVE FROM COMMENT LATER\n",
    "\n",
    "words = [row.split(' ') for row in df['review_body']]\n",
    "\n",
    "# train your own word2vec model\n",
    "\n",
    "model = gensim.models.Word2Vec(words, min_count=10,size=300,workers=3, window=11, sg=1)\n",
    "\n",
    "# summarize the loaded model\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=34607, size=300, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "# save model\n",
    "\n",
    "model.save('model.bin')\n",
    "\n",
    "# load saved model\n",
    "\n",
    "final_model = gensim.models.Word2Vec.load('model.bin')\n",
    "print(final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Arthur', 0.5806456208229065)]\n",
      "\n",
      "\n",
      "Semantic(Cosine) similarity between the two vectors is: 0.4015107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-28-1cf12555a4bb>:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  vec_King = final_model['King']\n",
      "<ipython-input-28-1cf12555a4bb>:2: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  vec_Man = final_model['Man']\n",
      "<ipython-input-28-1cf12555a4bb>:3: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  vec_Woman = final_model['Woman']\n",
      "<ipython-input-28-1cf12555a4bb>:4: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  vec_Queen = final_model['Queen']\n",
      "<ipython-input-28-1cf12555a4bb>:11: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  print(final_model.most_similar(positive=['King','Woman'], negative=['Man'], topn=1))\n"
     ]
    }
   ],
   "source": [
    "vec_King = final_model['King']\n",
    "vec_Man = final_model['Man']\n",
    "vec_Woman = final_model['Woman']\n",
    "vec_Queen = final_model['Queen']\n",
    "\n",
    "vec_1 = vec_King-vec_Man+vec_Woman\n",
    "vec_2 = vec_Queen\n",
    "\n",
    "# find out the similarity of the vectors using 'most_similar' function\n",
    "\n",
    "print(final_model.most_similar(positive=['King','Woman'], negative=['Man'], topn=1))\n",
    "print('\\n')\n",
    "\n",
    "# find out the similarity of the vectors using cosine similarity \n",
    "\n",
    "cosine_similarity = np.dot(vec_1,vec_2)/(np.linalg.norm(vec_1)* np.linalg.norm(vec_2))\n",
    "print(\"Semantic(Cosine) similarity between the two vectors is:\",cosine_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'excellent'\t'outstanding'\t0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-29-2c93295bc140>:3: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  print('%r\\t%r\\t%.2f' % (w1, w2, final_model.similarity('excellent', 'outstanding')))\n"
     ]
    }
   ],
   "source": [
    "# find out the similarity of the words\n",
    "\n",
    "print('%r\\t%r\\t%.2f' % (w1, w2, final_model.similarity('excellent', 'outstanding')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comments about this question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen from above,the vectors generated by our word2vec model are able to encode semantic similarities better between the words 'excellent ' and 'outstanding'(Word2Vec-0.67, Google-0.56). However the google model does slighlty better when it comes to the case of 'King - Man + Woman' and 'Queen'(Google-0.44, Word2Vec-0.40). Also it can be noted that the most similar word predicted to 'King - Man + Woman' is 'Queen' by the Google model but 'Arthur' by our model. This might likely be because the Google model has a larger word vocabulary and contains more common words. Also, since  we have taken these parameters for our Word2Vec model -(min_count=10,size=300,workers=3, window=11) , it isn't as refined as it could be potentially, thus leading to slightly low results in some cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Simple models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://www.amazon.com/review/create-review/ref=cm_cr_dp_wrt_summary?ie=utf8&asin=b00xp0d9p0\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/bs4/__init__.py:332: MarkupResemblesLocatorWarning: \".\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i assumed there were four chargers when i boug...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>my son likes to cook hes especially good with ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shipped fast good price they were way huger th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>containers are great but the lids are very thi...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>item was received broken i returned it and ask...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249995</th>\n",
       "      <td>the locks come off easily and they are hard to...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249996</th>\n",
       "      <td>i was bummed the carafe is slightly too wide a...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249997</th>\n",
       "      <td>I have had this kettle for just over one month...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249998</th>\n",
       "      <td>the idea and color of the balloons is enticing...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249999</th>\n",
       "      <td>product failed almost immediately digits garbl...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review_body  class\n",
       "0       i assumed there were four chargers when i boug...      2\n",
       "1       my son likes to cook hes especially good with ...      1\n",
       "2       shipped fast good price they were way huger th...      1\n",
       "3       containers are great but the lids are very thi...      3\n",
       "4       item was received broken i returned it and ask...      2\n",
       "...                                                   ...    ...\n",
       "249995  the locks come off easily and they are hard to...      3\n",
       "249996  i was bummed the carafe is slightly too wide a...      2\n",
       "249997  I have had this kettle for just over one month...      2\n",
       "249998  the idea and color of the balloons is enticing...      2\n",
       "249999  product failed almost immediately digits garbl...      2\n",
       "\n",
       "[250000 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the reviews column to string type\n",
    "\n",
    "df['review_body'] = df['review_body'].astype(str)\n",
    "\n",
    "# convert the reviews column to lower case\n",
    "\n",
    "df['review_body'] = df['review_body'].str.lower()\n",
    "\n",
    "# using BeautifulSoup, remove HTML tags from the reviews column\n",
    "\n",
    "# function to remove HTML tags\n",
    "def remove_html(string):\n",
    "  \n",
    "    # parse through html content\n",
    "    bs = BeautifulSoup(string, \"html.parser\")\n",
    "  \n",
    "    for text in bs(['style', 'script']):\n",
    "        # remove the tags\n",
    "        text.decompose()\n",
    "  \n",
    "    # return data by retrieving the tag content\n",
    "    return ' '.join(bs.stripped_strings)\n",
    "\n",
    "# apply the remove_html function to the reviews column\n",
    "\n",
    "df['review_body']=df['review_body'].apply(lambda x : remove_html(x))\n",
    "\n",
    "# using RegEx, remove URLs from the reviews column\n",
    "\n",
    "# function to remove URLS\n",
    "def remove_url(string):\n",
    "    result = re.sub(r'^https?:\\/\\/.*[\\r\\n]*',r' ', string, flags=re.MULTILINE)\n",
    "    return result\n",
    "\n",
    "# apply the remove_url function to the reviews column\n",
    "\n",
    "df['review_body']=df['review_body'].apply(lambda x : remove_url(x))\n",
    "\n",
    "# using RegEx, remove the characters apart from alphabets and single apostrophe(required for contractions later) from the reviews column and replace them with a single space \n",
    "\n",
    "df['review_body'] = df['review_body'].replace(r\"[^a-zA-Z' ]\\s?\",\" \",regex=True)\n",
    "\n",
    "# replace the single apostrophe with no space\n",
    "\n",
    "df['review_body'] = df['review_body'].replace(\"'\",\"\",regex=True)\n",
    "\n",
    "# using RegEx, remove the extra spaces between words from the reviews column\n",
    "\n",
    "df['review_body'] = df['review_body'].replace('\\s+', ' ', regex=True)\n",
    "\n",
    "# using the contractions library, perform contractions on the reviews \n",
    "\n",
    "df['review_body'] = df['review_body'].apply(lambda x: [contractions.fix(word) for word in x.split()])\n",
    "df['review_body'] = [' '.join(map(str, d)) for d in df['review_body']]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>assume four charger bought item pretty bought ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>son like cook he especially good grill burger ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ship fast good price way huger expect</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>container great lid thin break easily one use</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>item receive broken return ask replacement shi...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249995</th>\n",
       "      <td>lock come easily hard clean top</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249996</th>\n",
       "      <td>bum carafe slightly wide bit short metal struc...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249997</th>\n",
       "      <td>I kettle one month leak water leak seal bottom...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249998</th>\n",
       "      <td>idea color balloon entice order package child ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249999</th>\n",
       "      <td>product fail almost immediately digit garble s...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review_body  class\n",
       "0       assume four charger bought item pretty bought ...      2\n",
       "1       son like cook he especially good grill burger ...      1\n",
       "2                   ship fast good price way huger expect      1\n",
       "3           container great lid thin break easily one use      3\n",
       "4       item receive broken return ask replacement shi...      2\n",
       "...                                                   ...    ...\n",
       "249995                    lock come easily hard clean top      3\n",
       "249996  bum carafe slightly wide bit short metal struc...      2\n",
       "249997  I kettle one month leak water leak seal bottom...      2\n",
       "249998  idea color balloon entice order package child ...      2\n",
       "249999  product fail almost immediately digit garble s...      2\n",
       "\n",
       "[250000 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove all general stop words from the reviews column\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "df['review_body'] = df['review_body'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "\n",
    "# perform lemmatization with POS tagging \n",
    "\n",
    "whitespace_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "wordnet_lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "# funtion to return a POS form of a word\n",
    "def pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    pos_tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dictionary = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dictionary.get(pos_tag, wordnet.NOUN)\n",
    "\n",
    "# function to lemmatize the text\n",
    "def lemmatize_text(string):\n",
    "    return [wordnet_lemmatizer.lemmatize(w,pos(w)) for w in whitespace_tokenizer.tokenize(string)]\n",
    "\n",
    "df['review_body'] = df['review_body'].apply(lemmatize_text)\n",
    "df['review_body'] = [' '.join(map(str, l)) for l in df['review_body']]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>assume four charger bought item pretty bought ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>son like cook he especially good grill burger ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ship fast good price way huger expect</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>container great lid thin break easily one use</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>item receive broken return ask replacement shi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249995</th>\n",
       "      <td>lock come easily hard clean top</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249996</th>\n",
       "      <td>bum carafe slightly wide bit short metal struc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249997</th>\n",
       "      <td>I kettle one month leak water leak seal bottom...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249998</th>\n",
       "      <td>idea color balloon entice order package child ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249999</th>\n",
       "      <td>product fail almost immediately digit garble s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review_body  class\n",
       "0       assume four charger bought item pretty bought ...      1\n",
       "1       son like cook he especially good grill burger ...      0\n",
       "2                   ship fast good price way huger expect      0\n",
       "3           container great lid thin break easily one use      2\n",
       "4       item receive broken return ask replacement shi...      1\n",
       "...                                                   ...    ...\n",
       "249995                    lock come easily hard clean top      2\n",
       "249996  bum carafe slightly wide bit short metal struc...      1\n",
       "249997  I kettle one month leak water leak seal bottom...      1\n",
       "249998  idea color balloon entice order package child ...      1\n",
       "249999  product fail almost immediately digit garble s...      1\n",
       "\n",
       "[250000 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subtract target class values by 1 so that it becomes easier later on while comparison \n",
    "\n",
    "df['class'] = df['class']-1\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to find the average of vectors as your input feature \n",
    "\n",
    "def find_average_of_vectors(review,model_used):\n",
    "\n",
    "    sentence_words = review.split(\" \")\n",
    "    \n",
    "    sentence_vectors = []    \n",
    "    for word in sentence_words:\n",
    "        try:\n",
    "            sentence_vectors.append(model_used[word])\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    if len(sentence_vectors)!=0:\n",
    "        return (np.mean(sentence_vectors,axis=0)).flatten()\n",
    "    else:\n",
    "        return np.zeros((300,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>assume four charger bought item pretty bought ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>son like cook he especially good grill burger ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ship fast good price way huger expect</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>container great lid thin break easily one use</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>item receive broken return ask replacement shi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249995</th>\n",
       "      <td>lock come easily hard clean top</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249996</th>\n",
       "      <td>bum carafe slightly wide bit short metal struc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249997</th>\n",
       "      <td>I kettle one month leak water leak seal bottom...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249998</th>\n",
       "      <td>idea color balloon entice order package child ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249999</th>\n",
       "      <td>product fail almost immediately digit garble s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review_body  class\n",
       "0       assume four charger bought item pretty bought ...      1\n",
       "1       son like cook he especially good grill burger ...      0\n",
       "2                   ship fast good price way huger expect      0\n",
       "3           container great lid thin break easily one use      2\n",
       "4       item receive broken return ask replacement shi...      1\n",
       "...                                                   ...    ...\n",
       "249995                    lock come easily hard clean top      2\n",
       "249996  bum carafe slightly wide bit short metal struc...      1\n",
       "249997  I kettle one month leak water leak seal bottom...      1\n",
       "249998  idea color balloon entice order package child ...      1\n",
       "249999  product fail almost immediately digit garble s...      1\n",
       "\n",
       "[250000 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a copy of the original data frame(with data cleaning)\n",
    "\n",
    "df_org_3 = df.copy(deep=True)\n",
    "df_org_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "      <th>class</th>\n",
       "      <th>avg_input_features_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>assume four charger bought item pretty bought ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.04277208, -0.03597005, -0.062435575, 0.1046...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>son like cook he especially good grill burger ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.004893621, 0.029286703, -0.01199023, 0.162...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ship fast good price way huger expect</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.1432408, 0.08569336, -0.048673358, 0.078264...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>container great lid thin break easily one use</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.056274414, 0.10064697, -0.0005340576, 0.056...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>item receive broken return ask replacement shi...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.043584187, -0.013412476, -0.116475426, 0.06...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249995</th>\n",
       "      <td>lock come easily hard clean top</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.03120931, 0.07987467, 0.03741455, 0.0357869...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249996</th>\n",
       "      <td>bum carafe slightly wide bit short metal struc...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.001551011, 0.026309744, -0.06418026, 0.125...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249997</th>\n",
       "      <td>I kettle one month leak water leak seal bottom...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0027923584, 0.092679344, -0.03684489, 0.028...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249998</th>\n",
       "      <td>idea color balloon entice order package child ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.047094908, 0.011726828, 0.00012925093, 0.09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249999</th>\n",
       "      <td>product fail almost immediately digit garble s...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.085134655, -0.011324369, 0.06199294, 0.0255...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review_body  class  \\\n",
       "0       assume four charger bought item pretty bought ...      1   \n",
       "1       son like cook he especially good grill burger ...      0   \n",
       "2                   ship fast good price way huger expect      0   \n",
       "3           container great lid thin break easily one use      2   \n",
       "4       item receive broken return ask replacement shi...      1   \n",
       "...                                                   ...    ...   \n",
       "249995                    lock come easily hard clean top      2   \n",
       "249996  bum carafe slightly wide bit short metal struc...      1   \n",
       "249997  I kettle one month leak water leak seal bottom...      1   \n",
       "249998  idea color balloon entice order package child ...      1   \n",
       "249999  product fail almost immediately digit garble s...      1   \n",
       "\n",
       "                                     avg_input_features_1  \n",
       "0       [0.04277208, -0.03597005, -0.062435575, 0.1046...  \n",
       "1       [-0.004893621, 0.029286703, -0.01199023, 0.162...  \n",
       "2       [0.1432408, 0.08569336, -0.048673358, 0.078264...  \n",
       "3       [0.056274414, 0.10064697, -0.0005340576, 0.056...  \n",
       "4       [0.043584187, -0.013412476, -0.116475426, 0.06...  \n",
       "...                                                   ...  \n",
       "249995  [0.03120931, 0.07987467, 0.03741455, 0.0357869...  \n",
       "249996  [-0.001551011, 0.026309744, -0.06418026, 0.125...  \n",
       "249997  [0.0027923584, 0.092679344, -0.03684489, 0.028...  \n",
       "249998  [0.047094908, 0.011726828, 0.00012925093, 0.09...  \n",
       "249999  [0.085134655, -0.011324369, 0.06199294, 0.0255...  \n",
       "\n",
       "[250000 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find input feature for google model\n",
    "\n",
    "df_org_3['avg_input_features_1'] = df_org_3['review_body'].apply(lambda x: find_average_of_vectors(x,wv))\n",
    "df_org_3    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-6192696cc0bb>:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  sentence_vectors.append(model_used[word])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "      <th>class</th>\n",
       "      <th>avg_input_features_1</th>\n",
       "      <th>avg_input_features_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>assume four charger bought item pretty bought ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.04277208, -0.03597005, -0.062435575, 0.1046...</td>\n",
       "      <td>[0.017703589, -0.11186184, -0.0030522645, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>son like cook he especially good grill burger ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.004893621, 0.029286703, -0.01199023, 0.162...</td>\n",
       "      <td>[0.120273024, -0.14361034, 0.046780374, -0.138...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ship fast good price way huger expect</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.1432408, 0.08569336, -0.048673358, 0.078264...</td>\n",
       "      <td>[-0.049596105, -0.018341891, 0.13302507, -0.17...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>container great lid thin break easily one use</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.056274414, 0.10064697, -0.0005340576, 0.056...</td>\n",
       "      <td>[0.030435072, -0.15327847, 0.11309578, -0.1425...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>item receive broken return ask replacement shi...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.043584187, -0.013412476, -0.116475426, 0.06...</td>\n",
       "      <td>[0.08915458, -0.22801971, -0.028520422, -0.263...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249995</th>\n",
       "      <td>lock come easily hard clean top</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.03120931, 0.07987467, 0.03741455, 0.0357869...</td>\n",
       "      <td>[0.015699785, -0.12990652, 0.21889718, -0.1027...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249996</th>\n",
       "      <td>bum carafe slightly wide bit short metal struc...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.001551011, 0.026309744, -0.06418026, 0.125...</td>\n",
       "      <td>[0.015504825, -0.031771064, 0.1092756, -0.0557...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249997</th>\n",
       "      <td>I kettle one month leak water leak seal bottom...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0027923584, 0.092679344, -0.03684489, 0.028...</td>\n",
       "      <td>[0.020719932, -0.090553395, 0.13070571, -0.027...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249998</th>\n",
       "      <td>idea color balloon entice order package child ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.047094908, 0.011726828, 0.00012925093, 0.09...</td>\n",
       "      <td>[0.066825956, -0.17564225, 0.05628306, -0.0763...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249999</th>\n",
       "      <td>product fail almost immediately digit garble s...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.085134655, -0.011324369, 0.06199294, 0.0255...</td>\n",
       "      <td>[0.0051919767, -0.1441225, 0.13658296, -0.1857...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review_body  class  \\\n",
       "0       assume four charger bought item pretty bought ...      1   \n",
       "1       son like cook he especially good grill burger ...      0   \n",
       "2                   ship fast good price way huger expect      0   \n",
       "3           container great lid thin break easily one use      2   \n",
       "4       item receive broken return ask replacement shi...      1   \n",
       "...                                                   ...    ...   \n",
       "249995                    lock come easily hard clean top      2   \n",
       "249996  bum carafe slightly wide bit short metal struc...      1   \n",
       "249997  I kettle one month leak water leak seal bottom...      1   \n",
       "249998  idea color balloon entice order package child ...      1   \n",
       "249999  product fail almost immediately digit garble s...      1   \n",
       "\n",
       "                                     avg_input_features_1  \\\n",
       "0       [0.04277208, -0.03597005, -0.062435575, 0.1046...   \n",
       "1       [-0.004893621, 0.029286703, -0.01199023, 0.162...   \n",
       "2       [0.1432408, 0.08569336, -0.048673358, 0.078264...   \n",
       "3       [0.056274414, 0.10064697, -0.0005340576, 0.056...   \n",
       "4       [0.043584187, -0.013412476, -0.116475426, 0.06...   \n",
       "...                                                   ...   \n",
       "249995  [0.03120931, 0.07987467, 0.03741455, 0.0357869...   \n",
       "249996  [-0.001551011, 0.026309744, -0.06418026, 0.125...   \n",
       "249997  [0.0027923584, 0.092679344, -0.03684489, 0.028...   \n",
       "249998  [0.047094908, 0.011726828, 0.00012925093, 0.09...   \n",
       "249999  [0.085134655, -0.011324369, 0.06199294, 0.0255...   \n",
       "\n",
       "                                     avg_input_features_2  \n",
       "0       [0.017703589, -0.11186184, -0.0030522645, -0.0...  \n",
       "1       [0.120273024, -0.14361034, 0.046780374, -0.138...  \n",
       "2       [-0.049596105, -0.018341891, 0.13302507, -0.17...  \n",
       "3       [0.030435072, -0.15327847, 0.11309578, -0.1425...  \n",
       "4       [0.08915458, -0.22801971, -0.028520422, -0.263...  \n",
       "...                                                   ...  \n",
       "249995  [0.015699785, -0.12990652, 0.21889718, -0.1027...  \n",
       "249996  [0.015504825, -0.031771064, 0.1092756, -0.0557...  \n",
       "249997  [0.020719932, -0.090553395, 0.13070571, -0.027...  \n",
       "249998  [0.066825956, -0.17564225, 0.05628306, -0.0763...  \n",
       "249999  [0.0051919767, -0.1441225, 0.13658296, -0.1857...  \n",
       "\n",
       "[250000 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find input feature for our model\n",
    "\n",
    "df_org_3['avg_input_features_2'] = df_org_3['review_body'].apply(lambda x: find_average_of_vectors(x,final_model))\n",
    "df_org_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "      <th>class</th>\n",
       "      <th>avg_input_features_1</th>\n",
       "      <th>avg_input_features_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>assume four charger bought item pretty bought ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.04277208, -0.03597005, -0.062435575, 0.1046...</td>\n",
       "      <td>[0.017703589, -0.11186184, -0.0030522645, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>son like cook he especially good grill burger ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.004893621, 0.029286703, -0.01199023, 0.162...</td>\n",
       "      <td>[0.120273024, -0.14361034, 0.046780374, -0.138...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ship fast good price way huger expect</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.1432408, 0.08569336, -0.048673358, 0.078264...</td>\n",
       "      <td>[-0.049596105, -0.018341891, 0.13302507, -0.17...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>item receive broken return ask replacement shi...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.043584187, -0.013412476, -0.116475426, 0.06...</td>\n",
       "      <td>[0.08915458, -0.22801971, -0.028520422, -0.263...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>experience issue one cup fill make sure filter...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0077209473, -0.015841166, -0.04876624, 0.11...</td>\n",
       "      <td>[0.0042549637, -0.026836593, 0.14918885, -0.08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249993</th>\n",
       "      <td>toaster oven fine especially since paid amazon...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.03401947, 0.05153087, -0.0007176717, 0.0253...</td>\n",
       "      <td>[0.050901376, -0.11194899, 0.12081799, -0.0080...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249996</th>\n",
       "      <td>bum carafe slightly wide bit short metal struc...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.001551011, 0.026309744, -0.06418026, 0.125...</td>\n",
       "      <td>[0.015504825, -0.031771064, 0.1092756, -0.0557...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249997</th>\n",
       "      <td>I kettle one month leak water leak seal bottom...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0027923584, 0.092679344, -0.03684489, 0.028...</td>\n",
       "      <td>[0.020719932, -0.090553395, 0.13070571, -0.027...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249998</th>\n",
       "      <td>idea color balloon entice order package child ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.047094908, 0.011726828, 0.00012925093, 0.09...</td>\n",
       "      <td>[0.066825956, -0.17564225, 0.05628306, -0.0763...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249999</th>\n",
       "      <td>product fail almost immediately digit garble s...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.085134655, -0.011324369, 0.06199294, 0.0255...</td>\n",
       "      <td>[0.0051919767, -0.1441225, 0.13658296, -0.1857...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review_body  class  \\\n",
       "0       assume four charger bought item pretty bought ...      1   \n",
       "1       son like cook he especially good grill burger ...      0   \n",
       "2                   ship fast good price way huger expect      0   \n",
       "4       item receive broken return ask replacement shi...      1   \n",
       "5       experience issue one cup fill make sure filter...      0   \n",
       "...                                                   ...    ...   \n",
       "249993  toaster oven fine especially since paid amazon...      1   \n",
       "249996  bum carafe slightly wide bit short metal struc...      1   \n",
       "249997  I kettle one month leak water leak seal bottom...      1   \n",
       "249998  idea color balloon entice order package child ...      1   \n",
       "249999  product fail almost immediately digit garble s...      1   \n",
       "\n",
       "                                     avg_input_features_1  \\\n",
       "0       [0.04277208, -0.03597005, -0.062435575, 0.1046...   \n",
       "1       [-0.004893621, 0.029286703, -0.01199023, 0.162...   \n",
       "2       [0.1432408, 0.08569336, -0.048673358, 0.078264...   \n",
       "4       [0.043584187, -0.013412476, -0.116475426, 0.06...   \n",
       "5       [0.0077209473, -0.015841166, -0.04876624, 0.11...   \n",
       "...                                                   ...   \n",
       "249993  [0.03401947, 0.05153087, -0.0007176717, 0.0253...   \n",
       "249996  [-0.001551011, 0.026309744, -0.06418026, 0.125...   \n",
       "249997  [0.0027923584, 0.092679344, -0.03684489, 0.028...   \n",
       "249998  [0.047094908, 0.011726828, 0.00012925093, 0.09...   \n",
       "249999  [0.085134655, -0.011324369, 0.06199294, 0.0255...   \n",
       "\n",
       "                                     avg_input_features_2  \n",
       "0       [0.017703589, -0.11186184, -0.0030522645, -0.0...  \n",
       "1       [0.120273024, -0.14361034, 0.046780374, -0.138...  \n",
       "2       [-0.049596105, -0.018341891, 0.13302507, -0.17...  \n",
       "4       [0.08915458, -0.22801971, -0.028520422, -0.263...  \n",
       "5       [0.0042549637, -0.026836593, 0.14918885, -0.08...  \n",
       "...                                                   ...  \n",
       "249993  [0.050901376, -0.11194899, 0.12081799, -0.0080...  \n",
       "249996  [0.015504825, -0.031771064, 0.1092756, -0.0557...  \n",
       "249997  [0.020719932, -0.090553395, 0.13070571, -0.027...  \n",
       "249998  [0.066825956, -0.17564225, 0.05628306, -0.0763...  \n",
       "249999  [0.0051919767, -0.1441225, 0.13658296, -0.1857...  \n",
       "\n",
       "[200000 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# binary classification dataframe\n",
    "\n",
    "df_binary = df_org_3[((df_org_3['class'] == 0) | (df_org_3['class'] == 1))]\n",
    "df_binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_binary['avg_input_features_1']\n",
    "y = df_binary['class']\n",
    "\n",
    "# Split the dataset into 80% training dataset and 20% testing dataset\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=100)\n",
    "\n",
    "x_train = x_train.tolist()\n",
    "x_test = x_test.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------Test-----------------------\n",
      "\n",
      "\n",
      "Accuracy of Perceptron Model: 0.710925\n"
     ]
    }
   ],
   "source": [
    "# train a Perceptron model on the training dataset\n",
    "\n",
    "perceptron = Perceptron(n_jobs=-1, random_state=100)\n",
    "perceptron.fit(x_train,y_train)\n",
    "\n",
    "# predict the labels of test values\n",
    "\n",
    "y_test_pred = perceptron.predict(x_test)\n",
    "\n",
    "# find the accuracy of the Perceptron model on the test set\n",
    "\n",
    "print(\"-----------------------Test-----------------------\")\n",
    "print('\\n')\n",
    "print(\"Accuracy of Perceptron Model:\",accuracy_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------Test-----------------------\n",
      "\n",
      "\n",
      "Accuracy of SVM Model: 0.819275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "# standardize the features using StandardScaler\n",
    "\n",
    "scalar = StandardScaler()\n",
    "x_train_std = scalar.fit_transform(x_train)\n",
    "x_test_std = scalar.transform(x_test)\n",
    "\n",
    "# train an SVM model on the training dataset\n",
    "\n",
    "lin_svc = LinearSVC(random_state=100)\n",
    "lin_svc.fit(x_train_std,y_train)\n",
    "\n",
    "# predict the labels of test values\n",
    "\n",
    "y_test_pred = lin_svc.predict(x_test_std)\n",
    "\n",
    "# find the accuracy of the SVM model on the test set\n",
    "\n",
    "print(\"-----------------------Test-----------------------\")\n",
    "print('\\n')\n",
    "print(\"Accuracy of SVM Model:\",accuracy_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_binary['avg_input_features_2']\n",
    "y = df_binary['class']\n",
    "\n",
    "# Split the dataset into 80% training dataset and 20% testing dataset\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=100)\n",
    "\n",
    "x_train = x_train.tolist()\n",
    "x_test = x_test.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------Test-----------------------\n",
      "\n",
      "\n",
      "Accuracy of Perceptron Model: 0.811125\n"
     ]
    }
   ],
   "source": [
    "# train a Perceptron model on the training dataset\n",
    "\n",
    "perceptron = Perceptron(n_jobs=-1, random_state=100)\n",
    "perceptron.fit(x_train,y_train)\n",
    "\n",
    "# predict the labels of test values\n",
    "\n",
    "y_test_pred = perceptron.predict(x_test)\n",
    "\n",
    "# find the accuracy of the Perceptron model on the test set\n",
    "\n",
    "print(\"-----------------------Test-----------------------\")\n",
    "print('\\n')\n",
    "print(\"Accuracy of Perceptron Model:\",accuracy_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------Test-----------------------\n",
      "\n",
      "\n",
      "Accuracy of SVM Model: 0.85065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "# standardize the features using StandardScaler\n",
    "\n",
    "scalar = StandardScaler()\n",
    "x_train_std = scalar.fit_transform(x_train)\n",
    "x_test_std = scalar.transform(x_test)\n",
    "\n",
    "# train an SVM model on the training dataset\n",
    "\n",
    "lin_svc = LinearSVC(random_state=100)\n",
    "lin_svc.fit(x_train_std,y_train)\n",
    "\n",
    "# predict the labels of test values\n",
    "\n",
    "y_test_pred = lin_svc.predict(x_test_std)\n",
    "\n",
    "# find the accuracy of the SVM model on the test set\n",
    "\n",
    "print(\"-----------------------Test-----------------------\")\n",
    "print('\\n')\n",
    "print(\"Accuracy of SVM Model:\",accuracy_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comments about this question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Word2Vec Features/Other Features</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>Google News</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>Google News</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>Amazon Reviews(Our)</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>Amazon Reviews(Our)</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Model Word2Vec Features/Other Features Accuracy\n",
       "0  Perceptron                      Google News     0.71\n",
       "1         SVM                      Google News     0.82\n",
       "2  Perceptron              Amazon Reviews(Our)     0.81\n",
       "3         SVM              Amazon Reviews(Our)     0.85\n",
       "4  Perceptron                           TF-IDF     0.85\n",
       "5         SVM                           TF-IDF     0.81"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'Model': ['Perceptron', 'SVM', 'Perceptron', 'SVM', 'Perceptron', 'SVM'], \n",
    "     'Word2Vec Features/Other Features': ['Google News', 'Google News', 'Amazon Reviews(Our)', 'Amazon Reviews(Our)', 'TF-IDF', 'TF-IDF'],\n",
    "     'Accuracy': ['0.71', '0.82', '0.81', '0.85', '0.85', '0.81']}\n",
    "\n",
    "df_results_part_3 = pd.DataFrame(data=d)\n",
    "df_results_part_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen from the above table that the TF-IDF feature types give us the best accuracy for the perceptron model, followed by the our trained Word2Vec and then Google Word2Vec. However for the SVM model, the best accuracy is given by our trained Word2Vec, follwed by Google Word2Vec and then TF-IDF. This unstable order shows us that different features work for different models the best and there is no 'one glove fits all' / 'free lunch theorem' concept in the real world. Trying out different features and then choosing what works the best for that model(good feature selection) should be our optimal solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Feedforward Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# find out if GPU available\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set hyperparameters for all the models\n",
    "\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 20\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train data\n",
    "class trainData(Dataset):\n",
    "    \n",
    "    def __init__(self, x_data, y_data):\n",
    "        self.x_data = x_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.x_data)\n",
    "\n",
    "## test data    \n",
    "class testData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters \n",
    "\n",
    "input_size = 300\n",
    "hidden_1_size = 50\n",
    "hidden_2_size = 10\n",
    "output_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model for binary classification \n",
    "\n",
    "class binary_classification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(binary_classification, self).__init__()\n",
    "\n",
    "        self.layer_1 = nn.Linear(input_size, hidden_1_size) \n",
    "        self.layer_2 = nn.Linear(hidden_1_size, hidden_2_size)\n",
    "        self.layer_out = nn.Linear(hidden_2_size, output_size) \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(hidden_1_size)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(hidden_2_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.layer_1(x))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_classification(\n",
      "  (layer_1): Linear(in_features=300, out_features=50, bias=True)\n",
      "  (layer_2): Linear(in_features=50, out_features=10, bias=True)\n",
      "  (layer_out): Linear(in_features=10, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (batchnorm1): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm2): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# print model\n",
    "\n",
    "model = binary_classification()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function and optimizer\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to find the accuracy of the binary model\n",
    "\n",
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train the binary model and print results(loss & accuracy per epoch)\n",
    "\n",
    "def train_model_binary():\n",
    "    model.train()\n",
    "    for e in range(1, EPOCHS+1):\n",
    "        epoch_loss = 0\n",
    "        epoch_acc = 0\n",
    "\n",
    "        for x_batch, y_batch in train_loader:\n",
    "            x_batch, y_batch = x_batch, y_batch\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            y_pred = model(x_batch)\n",
    "\n",
    "            loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "            acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "\n",
    "        print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_binary(y_test):\n",
    "    model.eval()\n",
    "    \n",
    "    y_pred_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_batch in test_loader:\n",
    "            y_test_pred = model(x_batch)\n",
    "            y_pred_list.append(y_test_pred)\n",
    "    \n",
    "    y_pred_list = torch.FloatTensor(y_pred_list)\n",
    "    y_test = torch.FloatTensor(y_test.tolist())\n",
    "\n",
    "    accuracy = binary_acc(y_pred_list, y_test)\n",
    "    print(\"Accuracy:\",accuracy.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_binary['avg_input_features_1']\n",
    "y = df_binary['class']\n",
    "\n",
    "# Split the dataset into 80% training dataset and 20% testing dataset\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train data\n",
    "train_data = trainData(torch.FloatTensor(x_train.tolist()), \n",
    "                       torch.FloatTensor(y_train))\n",
    "## test data    \n",
    "test_data = testData(torch.FloatTensor(x_test.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Loss: 0.42925 | Acc: 80.427\n",
      "Epoch 002: | Loss: 0.41289 | Acc: 81.357\n",
      "Epoch 003: | Loss: 0.40518 | Acc: 81.923\n",
      "Epoch 004: | Loss: 0.40056 | Acc: 82.179\n",
      "Epoch 005: | Loss: 0.39944 | Acc: 82.272\n",
      "Epoch 006: | Loss: 0.39628 | Acc: 82.422\n",
      "Epoch 007: | Loss: 0.39473 | Acc: 82.412\n",
      "Epoch 008: | Loss: 0.39098 | Acc: 82.772\n",
      "Epoch 009: | Loss: 0.38844 | Acc: 82.825\n",
      "Epoch 010: | Loss: 0.38683 | Acc: 82.814\n",
      "Epoch 011: | Loss: 0.38560 | Acc: 83.001\n",
      "Epoch 012: | Loss: 0.38540 | Acc: 83.044\n",
      "Epoch 013: | Loss: 0.38458 | Acc: 83.044\n",
      "Epoch 014: | Loss: 0.38339 | Acc: 83.141\n",
      "Epoch 015: | Loss: 0.38325 | Acc: 83.186\n",
      "Epoch 016: | Loss: 0.38196 | Acc: 83.244\n",
      "Epoch 017: | Loss: 0.38092 | Acc: 83.311\n",
      "Epoch 018: | Loss: 0.37976 | Acc: 83.289\n",
      "Epoch 019: | Loss: 0.37805 | Acc: 83.453\n",
      "Epoch 020: | Loss: 0.37860 | Acc: 83.415\n",
      "Epoch 021: | Loss: 0.37704 | Acc: 83.559\n",
      "Epoch 022: | Loss: 0.37740 | Acc: 83.449\n",
      "Epoch 023: | Loss: 0.37587 | Acc: 83.499\n",
      "Epoch 024: | Loss: 0.37558 | Acc: 83.574\n",
      "Epoch 025: | Loss: 0.37523 | Acc: 83.603\n",
      "Epoch 026: | Loss: 0.37312 | Acc: 83.656\n",
      "Epoch 027: | Loss: 0.37383 | Acc: 83.618\n",
      "Epoch 028: | Loss: 0.37254 | Acc: 83.697\n",
      "Epoch 029: | Loss: 0.37153 | Acc: 83.736\n",
      "Epoch 030: | Loss: 0.37065 | Acc: 83.766\n",
      "Epoch 031: | Loss: 0.37226 | Acc: 83.739\n",
      "Epoch 032: | Loss: 0.37153 | Acc: 83.741\n",
      "Epoch 033: | Loss: 0.37182 | Acc: 83.778\n",
      "Epoch 034: | Loss: 0.37105 | Acc: 83.753\n",
      "Epoch 035: | Loss: 0.36988 | Acc: 83.822\n",
      "Epoch 036: | Loss: 0.36996 | Acc: 83.828\n",
      "Epoch 037: | Loss: 0.36943 | Acc: 83.866\n",
      "Epoch 038: | Loss: 0.36915 | Acc: 83.983\n",
      "Epoch 039: | Loss: 0.36818 | Acc: 83.968\n",
      "Epoch 040: | Loss: 0.36761 | Acc: 84.003\n",
      "Epoch 041: | Loss: 0.36854 | Acc: 83.972\n",
      "Epoch 042: | Loss: 0.36567 | Acc: 83.989\n",
      "Epoch 043: | Loss: 0.37031 | Acc: 83.805\n",
      "Epoch 044: | Loss: 0.36810 | Acc: 84.016\n",
      "Epoch 045: | Loss: 0.36753 | Acc: 83.921\n",
      "Epoch 046: | Loss: 0.36824 | Acc: 83.954\n",
      "Epoch 047: | Loss: 0.36747 | Acc: 83.938\n",
      "Epoch 048: | Loss: 0.36570 | Acc: 84.142\n",
      "Epoch 049: | Loss: 0.36674 | Acc: 84.014\n",
      "Epoch 050: | Loss: 0.36656 | Acc: 84.003\n",
      "Epoch 051: | Loss: 0.36587 | Acc: 83.988\n",
      "Epoch 052: | Loss: 0.36398 | Acc: 84.125\n",
      "Epoch 053: | Loss: 0.36465 | Acc: 84.112\n",
      "Epoch 054: | Loss: 0.36368 | Acc: 84.137\n",
      "Epoch 055: | Loss: 0.36503 | Acc: 84.052\n",
      "Epoch 056: | Loss: 0.36493 | Acc: 84.104\n",
      "Epoch 057: | Loss: 0.36615 | Acc: 84.062\n",
      "Epoch 058: | Loss: 0.36452 | Acc: 84.069\n",
      "Epoch 059: | Loss: 0.36342 | Acc: 84.144\n",
      "Epoch 060: | Loss: 0.36419 | Acc: 84.156\n",
      "Epoch 061: | Loss: 0.36340 | Acc: 84.156\n",
      "Epoch 062: | Loss: 0.36301 | Acc: 84.171\n",
      "Epoch 063: | Loss: 0.36327 | Acc: 84.276\n",
      "Epoch 064: | Loss: 0.36113 | Acc: 84.282\n",
      "Epoch 065: | Loss: 0.36300 | Acc: 84.207\n",
      "Epoch 066: | Loss: 0.36089 | Acc: 84.371\n",
      "Epoch 067: | Loss: 0.36273 | Acc: 84.201\n",
      "Epoch 068: | Loss: 0.36160 | Acc: 84.259\n",
      "Epoch 069: | Loss: 0.36293 | Acc: 84.179\n",
      "Epoch 070: | Loss: 0.36180 | Acc: 84.256\n",
      "Epoch 071: | Loss: 0.36075 | Acc: 84.329\n",
      "Epoch 072: | Loss: 0.35986 | Acc: 84.395\n",
      "Epoch 073: | Loss: 0.36016 | Acc: 84.276\n",
      "Epoch 074: | Loss: 0.36162 | Acc: 84.318\n",
      "Epoch 075: | Loss: 0.36066 | Acc: 84.388\n",
      "Epoch 076: | Loss: 0.36014 | Acc: 84.353\n",
      "Epoch 077: | Loss: 0.36037 | Acc: 84.293\n",
      "Epoch 078: | Loss: 0.35928 | Acc: 84.394\n",
      "Epoch 079: | Loss: 0.36096 | Acc: 84.328\n",
      "Epoch 080: | Loss: 0.36057 | Acc: 84.340\n",
      "Epoch 081: | Loss: 0.35967 | Acc: 84.464\n",
      "Epoch 082: | Loss: 0.35982 | Acc: 84.394\n",
      "Epoch 083: | Loss: 0.36015 | Acc: 84.395\n",
      "Epoch 084: | Loss: 0.36111 | Acc: 84.306\n",
      "Epoch 085: | Loss: 0.35828 | Acc: 84.454\n",
      "Epoch 086: | Loss: 0.35949 | Acc: 84.453\n",
      "Epoch 087: | Loss: 0.35876 | Acc: 84.383\n",
      "Epoch 088: | Loss: 0.36024 | Acc: 84.416\n",
      "Epoch 089: | Loss: 0.35979 | Acc: 84.473\n",
      "Epoch 090: | Loss: 0.35988 | Acc: 84.357\n",
      "Epoch 091: | Loss: 0.35880 | Acc: 84.451\n",
      "Epoch 092: | Loss: 0.35806 | Acc: 84.474\n",
      "Epoch 093: | Loss: 0.35785 | Acc: 84.506\n",
      "Epoch 094: | Loss: 0.35827 | Acc: 84.407\n",
      "Epoch 095: | Loss: 0.35978 | Acc: 84.424\n",
      "Epoch 096: | Loss: 0.35890 | Acc: 84.477\n",
      "Epoch 097: | Loss: 0.35662 | Acc: 84.542\n",
      "Epoch 098: | Loss: 0.35742 | Acc: 84.383\n",
      "Epoch 099: | Loss: 0.35740 | Acc: 84.368\n",
      "Epoch 100: | Loss: 0.35755 | Acc: 84.498\n"
     ]
    }
   ],
   "source": [
    "train_model_binary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 85.0\n"
     ]
    }
   ],
   "source": [
    "test_model_binary(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_binary['avg_input_features_2']\n",
    "y = df_binary['class']\n",
    "\n",
    "# Split the dataset into 80% training dataset and 20% testing dataset\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train data\n",
    "train_data = trainData(torch.FloatTensor(x_train.tolist()), \n",
    "                       torch.FloatTensor(y_train))\n",
    "## test data    \n",
    "test_data = testData(torch.FloatTensor(x_test.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Loss: 0.39232 | Acc: 82.813\n",
      "Epoch 002: | Loss: 0.36632 | Acc: 84.182\n",
      "Epoch 003: | Loss: 0.35946 | Acc: 84.547\n",
      "Epoch 004: | Loss: 0.35653 | Acc: 84.755\n",
      "Epoch 005: | Loss: 0.35471 | Acc: 84.800\n",
      "Epoch 006: | Loss: 0.35266 | Acc: 84.886\n",
      "Epoch 007: | Loss: 0.34956 | Acc: 85.044\n",
      "Epoch 008: | Loss: 0.34865 | Acc: 85.131\n",
      "Epoch 009: | Loss: 0.34677 | Acc: 85.244\n",
      "Epoch 010: | Loss: 0.34363 | Acc: 85.446\n",
      "Epoch 011: | Loss: 0.34300 | Acc: 85.409\n",
      "Epoch 012: | Loss: 0.34189 | Acc: 85.467\n",
      "Epoch 013: | Loss: 0.34211 | Acc: 85.509\n",
      "Epoch 014: | Loss: 0.34012 | Acc: 85.634\n",
      "Epoch 015: | Loss: 0.33893 | Acc: 85.728\n",
      "Epoch 016: | Loss: 0.33678 | Acc: 85.840\n",
      "Epoch 017: | Loss: 0.33812 | Acc: 85.809\n",
      "Epoch 018: | Loss: 0.33775 | Acc: 85.824\n",
      "Epoch 019: | Loss: 0.33789 | Acc: 85.814\n",
      "Epoch 020: | Loss: 0.33505 | Acc: 85.876\n",
      "Epoch 021: | Loss: 0.33324 | Acc: 85.933\n",
      "Epoch 022: | Loss: 0.33596 | Acc: 85.903\n",
      "Epoch 023: | Loss: 0.33278 | Acc: 86.058\n",
      "Epoch 024: | Loss: 0.33759 | Acc: 85.791\n",
      "Epoch 025: | Loss: 0.33218 | Acc: 86.116\n",
      "Epoch 026: | Loss: 0.33294 | Acc: 86.046\n",
      "Epoch 027: | Loss: 0.33325 | Acc: 86.049\n",
      "Epoch 028: | Loss: 0.33159 | Acc: 86.079\n",
      "Epoch 029: | Loss: 0.33284 | Acc: 86.114\n",
      "Epoch 030: | Loss: 0.33073 | Acc: 86.104\n",
      "Epoch 031: | Loss: 0.33017 | Acc: 86.072\n",
      "Epoch 032: | Loss: 0.32992 | Acc: 86.121\n",
      "Epoch 033: | Loss: 0.33085 | Acc: 86.138\n",
      "Epoch 034: | Loss: 0.32784 | Acc: 86.251\n",
      "Epoch 035: | Loss: 0.32973 | Acc: 86.232\n",
      "Epoch 036: | Loss: 0.32661 | Acc: 86.349\n",
      "Epoch 037: | Loss: 0.32801 | Acc: 86.297\n",
      "Epoch 038: | Loss: 0.32906 | Acc: 86.326\n",
      "Epoch 039: | Loss: 0.32786 | Acc: 86.201\n",
      "Epoch 040: | Loss: 0.32752 | Acc: 86.188\n",
      "Epoch 041: | Loss: 0.32987 | Acc: 86.116\n",
      "Epoch 042: | Loss: 0.32918 | Acc: 86.251\n",
      "Epoch 043: | Loss: 0.32669 | Acc: 86.330\n",
      "Epoch 044: | Loss: 0.32733 | Acc: 86.331\n",
      "Epoch 045: | Loss: 0.32391 | Acc: 86.441\n",
      "Epoch 046: | Loss: 0.32584 | Acc: 86.354\n",
      "Epoch 047: | Loss: 0.32441 | Acc: 86.426\n",
      "Epoch 048: | Loss: 0.32511 | Acc: 86.450\n",
      "Epoch 049: | Loss: 0.32569 | Acc: 86.408\n",
      "Epoch 050: | Loss: 0.32575 | Acc: 86.345\n",
      "Epoch 051: | Loss: 0.32466 | Acc: 86.412\n",
      "Epoch 052: | Loss: 0.32621 | Acc: 86.321\n",
      "Epoch 053: | Loss: 0.32728 | Acc: 86.236\n",
      "Epoch 054: | Loss: 0.32691 | Acc: 86.368\n",
      "Epoch 055: | Loss: 0.32392 | Acc: 86.382\n",
      "Epoch 056: | Loss: 0.32668 | Acc: 86.389\n",
      "Epoch 057: | Loss: 0.32294 | Acc: 86.537\n",
      "Epoch 058: | Loss: 0.32282 | Acc: 86.406\n",
      "Epoch 059: | Loss: 0.32060 | Acc: 86.579\n",
      "Epoch 060: | Loss: 0.32326 | Acc: 86.479\n",
      "Epoch 061: | Loss: 0.32210 | Acc: 86.441\n",
      "Epoch 062: | Loss: 0.32237 | Acc: 86.454\n",
      "Epoch 063: | Loss: 0.32480 | Acc: 86.324\n",
      "Epoch 064: | Loss: 0.32176 | Acc: 86.525\n",
      "Epoch 065: | Loss: 0.32265 | Acc: 86.436\n",
      "Epoch 066: | Loss: 0.32066 | Acc: 86.576\n",
      "Epoch 067: | Loss: 0.32243 | Acc: 86.452\n",
      "Epoch 068: | Loss: 0.32156 | Acc: 86.548\n",
      "Epoch 069: | Loss: 0.32088 | Acc: 86.634\n",
      "Epoch 070: | Loss: 0.31985 | Acc: 86.634\n",
      "Epoch 071: | Loss: 0.31822 | Acc: 86.700\n",
      "Epoch 072: | Loss: 0.31938 | Acc: 86.631\n",
      "Epoch 073: | Loss: 0.32076 | Acc: 86.593\n",
      "Epoch 074: | Loss: 0.31971 | Acc: 86.582\n",
      "Epoch 075: | Loss: 0.32273 | Acc: 86.504\n",
      "Epoch 076: | Loss: 0.32132 | Acc: 86.588\n",
      "Epoch 077: | Loss: 0.32099 | Acc: 86.567\n",
      "Epoch 078: | Loss: 0.31815 | Acc: 86.623\n",
      "Epoch 079: | Loss: 0.31833 | Acc: 86.688\n",
      "Epoch 080: | Loss: 0.32235 | Acc: 86.564\n",
      "Epoch 081: | Loss: 0.32186 | Acc: 86.558\n",
      "Epoch 082: | Loss: 0.32028 | Acc: 86.562\n",
      "Epoch 083: | Loss: 0.31744 | Acc: 86.709\n",
      "Epoch 084: | Loss: 0.31719 | Acc: 86.753\n",
      "Epoch 085: | Loss: 0.31888 | Acc: 86.501\n",
      "Epoch 086: | Loss: 0.31788 | Acc: 86.670\n",
      "Epoch 087: | Loss: 0.31918 | Acc: 86.711\n",
      "Epoch 088: | Loss: 0.31895 | Acc: 86.687\n",
      "Epoch 089: | Loss: 0.31959 | Acc: 86.677\n",
      "Epoch 090: | Loss: 0.31753 | Acc: 86.796\n",
      "Epoch 091: | Loss: 0.31670 | Acc: 86.814\n",
      "Epoch 092: | Loss: 0.31715 | Acc: 86.686\n",
      "Epoch 093: | Loss: 0.31750 | Acc: 86.789\n",
      "Epoch 094: | Loss: 0.31823 | Acc: 86.680\n",
      "Epoch 095: | Loss: 0.31642 | Acc: 86.716\n",
      "Epoch 096: | Loss: 0.31713 | Acc: 86.763\n",
      "Epoch 097: | Loss: 0.31738 | Acc: 86.708\n",
      "Epoch 098: | Loss: 0.31473 | Acc: 86.873\n",
      "Epoch 099: | Loss: 0.31520 | Acc: 86.819\n",
      "Epoch 100: | Loss: 0.31742 | Acc: 86.736\n"
     ]
    }
   ],
   "source": [
    "train_model_binary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.0\n"
     ]
    }
   ],
   "source": [
    "test_model_binary(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ternary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "      <th>class</th>\n",
       "      <th>avg_input_features_1</th>\n",
       "      <th>avg_input_features_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>send back unhappy wth quality guage s sheet us...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.028214889, 0.054062814, 0.022171944, 0.065...</td>\n",
       "      <td>[0.016383082, -0.11017842, 0.07979045, -0.1103...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bought bottle week lid crack right rim boght p...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.009401504, 0.04494009, -0.01879862, 0.04671...</td>\n",
       "      <td>[0.0027814035, -0.1517246, 0.039110575, -0.084...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>good overall instruction could use improvement...</td>\n",
       "      <td>2</td>\n",
       "      <td>[-0.025609551, 0.035386518, -0.03870993, 0.123...</td>\n",
       "      <td>[-0.019544542, -0.09348309, 0.091074795, -0.08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>beautiful color unexpectedly large</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.051719666, 0.07980347, -0.05140686, 0.07983...</td>\n",
       "      <td>[-0.0066354196, -0.07669535, 0.14650348, 0.051...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>puzzle review look fine bought mug use clean t...</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0021718915, 0.036595784, -0.015984524, 0.04...</td>\n",
       "      <td>[0.049097426, -0.15116577, 0.034840178, -0.083...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249995</th>\n",
       "      <td>love little skinny spatula use stovetop cookin...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.032534514, 0.028369326, 0.016048547, 0.0922...</td>\n",
       "      <td>[0.07504659, -0.11023586, 0.102279335, -0.0310...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249996</th>\n",
       "      <td>cheap leaky creaky sure pump handle break soon...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.019851685, 0.074625395, -0.054214478, 0.047...</td>\n",
       "      <td>[-0.007991508, -0.23522964, 0.17086153, -0.027...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249997</th>\n",
       "      <td>good price awesome product buy constantly rest...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.027029855, -0.028424945, -0.025542123, 0.14...</td>\n",
       "      <td>[-0.01619439, -0.05732434, 0.008259937, -0.110...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249998</th>\n",
       "      <td>machine little loud make great cup coffee</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0011160715, -0.0034005302, -0.033098493, 0....</td>\n",
       "      <td>[0.0053175413, -0.09154149, 0.12706958, -0.087...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249999</th>\n",
       "      <td>portable go anywhere wine cup would probably g...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.020776367, 0.000773112, -0.021533202, 0.12...</td>\n",
       "      <td>[0.016355243, -0.13739465, -0.052232314, -0.01...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review_body  class  \\\n",
       "0       send back unhappy wth quality guage s sheet us...      1   \n",
       "1       bought bottle week lid crack right rim boght p...      1   \n",
       "2       good overall instruction could use improvement...      2   \n",
       "3                      beautiful color unexpectedly large      0   \n",
       "4       puzzle review look fine bought mug use clean t...      2   \n",
       "...                                                   ...    ...   \n",
       "249995  love little skinny spatula use stovetop cookin...      0   \n",
       "249996  cheap leaky creaky sure pump handle break soon...      1   \n",
       "249997  good price awesome product buy constantly rest...      0   \n",
       "249998          machine little loud make great cup coffee      0   \n",
       "249999  portable go anywhere wine cup would probably g...      1   \n",
       "\n",
       "                                     avg_input_features_1  \\\n",
       "0       [-0.028214889, 0.054062814, 0.022171944, 0.065...   \n",
       "1       [0.009401504, 0.04494009, -0.01879862, 0.04671...   \n",
       "2       [-0.025609551, 0.035386518, -0.03870993, 0.123...   \n",
       "3       [0.051719666, 0.07980347, -0.05140686, 0.07983...   \n",
       "4       [0.0021718915, 0.036595784, -0.015984524, 0.04...   \n",
       "...                                                   ...   \n",
       "249995  [0.032534514, 0.028369326, 0.016048547, 0.0922...   \n",
       "249996  [0.019851685, 0.074625395, -0.054214478, 0.047...   \n",
       "249997  [0.027029855, -0.028424945, -0.025542123, 0.14...   \n",
       "249998  [0.0011160715, -0.0034005302, -0.033098493, 0....   \n",
       "249999  [-0.020776367, 0.000773112, -0.021533202, 0.12...   \n",
       "\n",
       "                                     avg_input_features_2  \n",
       "0       [0.016383082, -0.11017842, 0.07979045, -0.1103...  \n",
       "1       [0.0027814035, -0.1517246, 0.039110575, -0.084...  \n",
       "2       [-0.019544542, -0.09348309, 0.091074795, -0.08...  \n",
       "3       [-0.0066354196, -0.07669535, 0.14650348, 0.051...  \n",
       "4       [0.049097426, -0.15116577, 0.034840178, -0.083...  \n",
       "...                                                   ...  \n",
       "249995  [0.07504659, -0.11023586, 0.102279335, -0.0310...  \n",
       "249996  [-0.007991508, -0.23522964, 0.17086153, -0.027...  \n",
       "249997  [-0.01619439, -0.05732434, 0.008259937, -0.110...  \n",
       "249998  [0.0053175413, -0.09154149, 0.12706958, -0.087...  \n",
       "249999  [0.016355243, -0.13739465, -0.052232314, -0.01...  \n",
       "\n",
       "[250000 rows x 4 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ternary classification dataframe\n",
    "\n",
    "df_ternary = df_org_3.copy(deep=True)\n",
    "df_ternary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters \n",
    "\n",
    "input_size = 300\n",
    "hidden_1_size = 50\n",
    "hidden_2_size = 10\n",
    "output_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model for ternary classification \n",
    "\n",
    "class ternary_classification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ternary_classification, self).__init__()\n",
    "        # Number of input features is 300.\n",
    "        self.layer_1 = nn.Linear(input_size, hidden_1_size) \n",
    "        self.layer_2 = nn.Linear(hidden_1_size, hidden_2_size)\n",
    "        self.layer_out = nn.Linear(hidden_2_size, output_size) \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(hidden_1_size)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(hidden_2_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.layer_1(x))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ternary_classification(\n",
      "  (layer_1): Linear(in_features=300, out_features=50, bias=True)\n",
      "  (layer_2): Linear(in_features=50, out_features=10, bias=True)\n",
      "  (layer_out): Linear(in_features=10, out_features=3, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (batchnorm1): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm2): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# print model\n",
    "\n",
    "model = ternary_classification()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function and optimizer\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to find the accuracy of the ternary model\n",
    "\n",
    "def ternary_acc(y_pred, y_test):\n",
    "    y_pred_softmax = torch.log_softmax(y_pred, dim = 1)\n",
    "    y_pred_tags = torch.argmax(y_pred_softmax, dim = 1)\n",
    "    \n",
    "    correct_pred = (y_pred_tags == y_test).float()\n",
    "    acc = correct_pred.sum() / len(correct_pred)\n",
    "    \n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train the ternary model and print results(loss & accuracy per epoch)\n",
    "\n",
    "def train_model_ternary():\n",
    "    model.train()\n",
    "    for e in range(1, EPOCHS+1):\n",
    "        epoch_loss = 0\n",
    "        epoch_acc = 0\n",
    "\n",
    "        for x_batch, y_batch in train_loader:\n",
    "            x_batch, y_batch = x_batch, y_batch\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            y_pred = model(x_batch)\n",
    "\n",
    "            loss = criterion(y_pred, y_batch.type(torch.LongTensor))\n",
    "            acc = ternary_acc(y_pred, y_batch.type(torch.LongTensor))\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "\n",
    "        print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_ternary(y_test):\n",
    "    model.eval()\n",
    "    \n",
    "    y_pred_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_batch in test_loader:\n",
    "            y_test_pred = model(x_batch)\n",
    "            y_pred_list.extend(y_test_pred.tolist())\n",
    "    \n",
    "    y_pred_list = torch.FloatTensor(y_pred_list)\n",
    "    y_test = torch.FloatTensor(y_test.tolist())\n",
    "\n",
    "    accuracy = ternary_acc(y_pred_list, y_test)\n",
    "    print(\"Accuracy:\",accuracy.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_ternary['avg_input_features_1']\n",
    "y = df_ternary['class']\n",
    "\n",
    "# Split the dataset into 80% training dataset and 20% testing dataset\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train data\n",
    "train_data = trainData(torch.FloatTensor(x_train.tolist()), \n",
    "                       torch.FloatTensor(y_train))\n",
    "## test data    \n",
    "test_data = testData(torch.FloatTensor(x_test.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Loss: 0.81074 | Acc: 64.684\n",
      "Epoch 002: | Loss: 0.79038 | Acc: 65.774\n",
      "Epoch 003: | Loss: 0.78350 | Acc: 66.063\n",
      "Epoch 004: | Loss: 0.77975 | Acc: 66.197\n",
      "Epoch 005: | Loss: 0.77602 | Acc: 66.421\n",
      "Epoch 006: | Loss: 0.77350 | Acc: 66.501\n",
      "Epoch 007: | Loss: 0.77049 | Acc: 66.802\n",
      "Epoch 008: | Loss: 0.76746 | Acc: 66.855\n",
      "Epoch 009: | Loss: 0.76838 | Acc: 66.906\n",
      "Epoch 010: | Loss: 0.76734 | Acc: 66.832\n",
      "Epoch 011: | Loss: 0.76561 | Acc: 66.938\n",
      "Epoch 012: | Loss: 0.76345 | Acc: 67.022\n",
      "Epoch 013: | Loss: 0.76225 | Acc: 67.181\n",
      "Epoch 014: | Loss: 0.76194 | Acc: 67.082\n",
      "Epoch 015: | Loss: 0.76024 | Acc: 67.168\n",
      "Epoch 016: | Loss: 0.76047 | Acc: 67.124\n",
      "Epoch 017: | Loss: 0.75881 | Acc: 67.260\n",
      "Epoch 018: | Loss: 0.75817 | Acc: 67.221\n",
      "Epoch 019: | Loss: 0.75690 | Acc: 67.308\n",
      "Epoch 020: | Loss: 0.75645 | Acc: 67.327\n",
      "Epoch 021: | Loss: 0.75610 | Acc: 67.394\n",
      "Epoch 022: | Loss: 0.75603 | Acc: 67.302\n",
      "Epoch 023: | Loss: 0.75522 | Acc: 67.371\n",
      "Epoch 024: | Loss: 0.75484 | Acc: 67.377\n",
      "Epoch 025: | Loss: 0.75271 | Acc: 67.562\n",
      "Epoch 026: | Loss: 0.75396 | Acc: 67.415\n",
      "Epoch 027: | Loss: 0.75273 | Acc: 67.512\n",
      "Epoch 028: | Loss: 0.75243 | Acc: 67.593\n",
      "Epoch 029: | Loss: 0.75331 | Acc: 67.391\n",
      "Epoch 030: | Loss: 0.75280 | Acc: 67.484\n",
      "Epoch 031: | Loss: 0.75049 | Acc: 67.660\n",
      "Epoch 032: | Loss: 0.75193 | Acc: 67.531\n",
      "Epoch 033: | Loss: 0.75154 | Acc: 67.484\n",
      "Epoch 034: | Loss: 0.75181 | Acc: 67.530\n",
      "Epoch 035: | Loss: 0.75151 | Acc: 67.629\n",
      "Epoch 036: | Loss: 0.75154 | Acc: 67.565\n",
      "Epoch 037: | Loss: 0.75164 | Acc: 67.579\n",
      "Epoch 038: | Loss: 0.75018 | Acc: 67.640\n",
      "Epoch 039: | Loss: 0.74989 | Acc: 67.638\n",
      "Epoch 040: | Loss: 0.75043 | Acc: 67.663\n",
      "Epoch 041: | Loss: 0.74842 | Acc: 67.745\n",
      "Epoch 042: | Loss: 0.74850 | Acc: 67.700\n",
      "Epoch 043: | Loss: 0.74778 | Acc: 67.737\n",
      "Epoch 044: | Loss: 0.74926 | Acc: 67.620\n",
      "Epoch 045: | Loss: 0.74831 | Acc: 67.674\n",
      "Epoch 046: | Loss: 0.74874 | Acc: 67.719\n",
      "Epoch 047: | Loss: 0.74880 | Acc: 67.709\n",
      "Epoch 048: | Loss: 0.75052 | Acc: 67.526\n",
      "Epoch 049: | Loss: 0.74793 | Acc: 67.635\n",
      "Epoch 050: | Loss: 0.74792 | Acc: 67.728\n",
      "Epoch 051: | Loss: 0.74723 | Acc: 67.850\n",
      "Epoch 052: | Loss: 0.74648 | Acc: 67.820\n",
      "Epoch 053: | Loss: 0.74730 | Acc: 67.649\n",
      "Epoch 054: | Loss: 0.74753 | Acc: 67.760\n",
      "Epoch 055: | Loss: 0.74507 | Acc: 67.840\n",
      "Epoch 056: | Loss: 0.74550 | Acc: 67.885\n",
      "Epoch 057: | Loss: 0.74431 | Acc: 67.954\n",
      "Epoch 058: | Loss: 0.74508 | Acc: 67.832\n",
      "Epoch 059: | Loss: 0.74524 | Acc: 67.882\n",
      "Epoch 060: | Loss: 0.74335 | Acc: 67.927\n",
      "Epoch 061: | Loss: 0.74466 | Acc: 67.864\n",
      "Epoch 062: | Loss: 0.74495 | Acc: 67.856\n",
      "Epoch 063: | Loss: 0.74414 | Acc: 67.969\n",
      "Epoch 064: | Loss: 0.74516 | Acc: 67.915\n",
      "Epoch 065: | Loss: 0.74569 | Acc: 67.849\n",
      "Epoch 066: | Loss: 0.74464 | Acc: 68.021\n",
      "Epoch 067: | Loss: 0.74411 | Acc: 67.951\n",
      "Epoch 068: | Loss: 0.74281 | Acc: 67.945\n",
      "Epoch 069: | Loss: 0.74328 | Acc: 68.031\n",
      "Epoch 070: | Loss: 0.74251 | Acc: 68.001\n",
      "Epoch 071: | Loss: 0.74331 | Acc: 67.944\n",
      "Epoch 072: | Loss: 0.74264 | Acc: 68.025\n",
      "Epoch 073: | Loss: 0.74215 | Acc: 67.987\n",
      "Epoch 074: | Loss: 0.74163 | Acc: 68.017\n",
      "Epoch 075: | Loss: 0.74275 | Acc: 67.941\n",
      "Epoch 076: | Loss: 0.74107 | Acc: 68.001\n",
      "Epoch 077: | Loss: 0.74220 | Acc: 68.114\n",
      "Epoch 078: | Loss: 0.74089 | Acc: 68.112\n",
      "Epoch 079: | Loss: 0.74065 | Acc: 68.055\n",
      "Epoch 080: | Loss: 0.74118 | Acc: 68.038\n",
      "Epoch 081: | Loss: 0.74213 | Acc: 68.025\n",
      "Epoch 082: | Loss: 0.74016 | Acc: 68.120\n",
      "Epoch 083: | Loss: 0.74056 | Acc: 68.160\n",
      "Epoch 084: | Loss: 0.74101 | Acc: 68.103\n",
      "Epoch 085: | Loss: 0.74093 | Acc: 68.191\n",
      "Epoch 086: | Loss: 0.74030 | Acc: 68.171\n",
      "Epoch 087: | Loss: 0.74051 | Acc: 68.052\n",
      "Epoch 088: | Loss: 0.74108 | Acc: 68.122\n",
      "Epoch 089: | Loss: 0.74125 | Acc: 68.064\n",
      "Epoch 090: | Loss: 0.74013 | Acc: 68.115\n",
      "Epoch 091: | Loss: 0.73998 | Acc: 68.145\n",
      "Epoch 092: | Loss: 0.74028 | Acc: 68.075\n",
      "Epoch 093: | Loss: 0.74015 | Acc: 68.190\n",
      "Epoch 094: | Loss: 0.74054 | Acc: 68.091\n",
      "Epoch 095: | Loss: 0.73964 | Acc: 68.181\n",
      "Epoch 096: | Loss: 0.74093 | Acc: 68.058\n",
      "Epoch 097: | Loss: 0.74063 | Acc: 68.108\n",
      "Epoch 098: | Loss: 0.74083 | Acc: 68.090\n",
      "Epoch 099: | Loss: 0.74134 | Acc: 68.052\n",
      "Epoch 100: | Loss: 0.74173 | Acc: 67.995\n"
     ]
    }
   ],
   "source": [
    "train_model_ternary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 68.0\n"
     ]
    }
   ],
   "source": [
    "test_model_ternary(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_ternary['avg_input_features_2']\n",
    "y = df_ternary['class']\n",
    "\n",
    "# Split the dataset into 80% training dataset and 20% testing dataset\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train data\n",
    "train_data = trainData(torch.FloatTensor(x_train.tolist()), \n",
    "                       torch.FloatTensor(y_train))\n",
    "## test data    \n",
    "test_data = testData(torch.FloatTensor(x_test.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Loss: 0.77657 | Acc: 66.731\n",
      "Epoch 002: | Loss: 0.74225 | Acc: 68.403\n",
      "Epoch 003: | Loss: 0.73529 | Acc: 68.714\n",
      "Epoch 004: | Loss: 0.73158 | Acc: 68.862\n",
      "Epoch 005: | Loss: 0.72965 | Acc: 69.052\n",
      "Epoch 006: | Loss: 0.72626 | Acc: 69.173\n",
      "Epoch 007: | Loss: 0.72531 | Acc: 69.286\n",
      "Epoch 008: | Loss: 0.72245 | Acc: 69.313\n",
      "Epoch 009: | Loss: 0.72162 | Acc: 69.436\n",
      "Epoch 010: | Loss: 0.72103 | Acc: 69.347\n",
      "Epoch 011: | Loss: 0.71931 | Acc: 69.397\n",
      "Epoch 012: | Loss: 0.71833 | Acc: 69.371\n",
      "Epoch 013: | Loss: 0.71758 | Acc: 69.464\n",
      "Epoch 014: | Loss: 0.71764 | Acc: 69.540\n",
      "Epoch 015: | Loss: 0.71575 | Acc: 69.572\n",
      "Epoch 016: | Loss: 0.71370 | Acc: 69.653\n",
      "Epoch 017: | Loss: 0.71389 | Acc: 69.635\n",
      "Epoch 018: | Loss: 0.71227 | Acc: 69.692\n",
      "Epoch 019: | Loss: 0.71149 | Acc: 69.790\n",
      "Epoch 020: | Loss: 0.71154 | Acc: 69.733\n",
      "Epoch 021: | Loss: 0.71211 | Acc: 69.715\n",
      "Epoch 022: | Loss: 0.70957 | Acc: 69.901\n",
      "Epoch 023: | Loss: 0.70945 | Acc: 69.834\n",
      "Epoch 024: | Loss: 0.70905 | Acc: 69.852\n",
      "Epoch 025: | Loss: 0.70729 | Acc: 69.925\n",
      "Epoch 026: | Loss: 0.70827 | Acc: 69.939\n",
      "Epoch 027: | Loss: 0.70631 | Acc: 70.046\n",
      "Epoch 028: | Loss: 0.70669 | Acc: 69.980\n",
      "Epoch 029: | Loss: 0.70660 | Acc: 69.948\n",
      "Epoch 030: | Loss: 0.70578 | Acc: 70.033\n",
      "Epoch 031: | Loss: 0.70609 | Acc: 69.958\n",
      "Epoch 032: | Loss: 0.70356 | Acc: 70.089\n",
      "Epoch 033: | Loss: 0.70564 | Acc: 69.979\n",
      "Epoch 034: | Loss: 0.70582 | Acc: 69.979\n",
      "Epoch 035: | Loss: 0.70407 | Acc: 70.093\n",
      "Epoch 036: | Loss: 0.70462 | Acc: 70.029\n",
      "Epoch 037: | Loss: 0.70317 | Acc: 70.019\n",
      "Epoch 038: | Loss: 0.70324 | Acc: 70.121\n",
      "Epoch 039: | Loss: 0.70374 | Acc: 70.100\n",
      "Epoch 040: | Loss: 0.70331 | Acc: 70.113\n",
      "Epoch 041: | Loss: 0.70262 | Acc: 70.254\n",
      "Epoch 042: | Loss: 0.70243 | Acc: 70.230\n",
      "Epoch 043: | Loss: 0.70184 | Acc: 70.207\n",
      "Epoch 044: | Loss: 0.70246 | Acc: 70.137\n",
      "Epoch 045: | Loss: 0.70267 | Acc: 70.207\n",
      "Epoch 046: | Loss: 0.70093 | Acc: 70.145\n",
      "Epoch 047: | Loss: 0.70168 | Acc: 70.052\n",
      "Epoch 048: | Loss: 0.70126 | Acc: 70.165\n",
      "Epoch 049: | Loss: 0.70104 | Acc: 70.173\n",
      "Epoch 050: | Loss: 0.70155 | Acc: 70.088\n",
      "Epoch 051: | Loss: 0.70091 | Acc: 70.188\n",
      "Epoch 052: | Loss: 0.70002 | Acc: 70.186\n",
      "Epoch 053: | Loss: 0.69958 | Acc: 70.287\n",
      "Epoch 054: | Loss: 0.69960 | Acc: 70.278\n",
      "Epoch 055: | Loss: 0.69968 | Acc: 70.224\n",
      "Epoch 056: | Loss: 0.69903 | Acc: 70.225\n",
      "Epoch 057: | Loss: 0.70024 | Acc: 70.218\n",
      "Epoch 058: | Loss: 0.69947 | Acc: 70.207\n",
      "Epoch 059: | Loss: 0.70004 | Acc: 70.185\n",
      "Epoch 060: | Loss: 0.69910 | Acc: 70.335\n",
      "Epoch 061: | Loss: 0.69808 | Acc: 70.245\n",
      "Epoch 062: | Loss: 0.69858 | Acc: 70.308\n",
      "Epoch 063: | Loss: 0.69851 | Acc: 70.347\n",
      "Epoch 064: | Loss: 0.69925 | Acc: 70.296\n",
      "Epoch 065: | Loss: 0.69895 | Acc: 70.294\n",
      "Epoch 066: | Loss: 0.69730 | Acc: 70.263\n",
      "Epoch 067: | Loss: 0.69818 | Acc: 70.249\n",
      "Epoch 068: | Loss: 0.69684 | Acc: 70.317\n",
      "Epoch 069: | Loss: 0.69691 | Acc: 70.312\n",
      "Epoch 070: | Loss: 0.69692 | Acc: 70.266\n",
      "Epoch 071: | Loss: 0.69770 | Acc: 70.221\n",
      "Epoch 072: | Loss: 0.69637 | Acc: 70.400\n",
      "Epoch 073: | Loss: 0.69646 | Acc: 70.243\n",
      "Epoch 074: | Loss: 0.69551 | Acc: 70.474\n",
      "Epoch 075: | Loss: 0.69519 | Acc: 70.481\n",
      "Epoch 076: | Loss: 0.69502 | Acc: 70.486\n",
      "Epoch 077: | Loss: 0.69615 | Acc: 70.392\n",
      "Epoch 078: | Loss: 0.69638 | Acc: 70.362\n",
      "Epoch 079: | Loss: 0.69513 | Acc: 70.421\n",
      "Epoch 080: | Loss: 0.69545 | Acc: 70.377\n",
      "Epoch 081: | Loss: 0.69569 | Acc: 70.394\n",
      "Epoch 082: | Loss: 0.69482 | Acc: 70.425\n",
      "Epoch 083: | Loss: 0.69612 | Acc: 70.404\n",
      "Epoch 084: | Loss: 0.69444 | Acc: 70.455\n",
      "Epoch 085: | Loss: 0.69469 | Acc: 70.415\n",
      "Epoch 086: | Loss: 0.69517 | Acc: 70.375\n",
      "Epoch 087: | Loss: 0.69511 | Acc: 70.459\n",
      "Epoch 088: | Loss: 0.69475 | Acc: 70.472\n",
      "Epoch 089: | Loss: 0.69380 | Acc: 70.490\n",
      "Epoch 090: | Loss: 0.69439 | Acc: 70.445\n",
      "Epoch 091: | Loss: 0.69405 | Acc: 70.450\n",
      "Epoch 092: | Loss: 0.69421 | Acc: 70.433\n",
      "Epoch 093: | Loss: 0.69460 | Acc: 70.404\n",
      "Epoch 094: | Loss: 0.69319 | Acc: 70.463\n",
      "Epoch 095: | Loss: 0.69391 | Acc: 70.307\n",
      "Epoch 096: | Loss: 0.69338 | Acc: 70.493\n",
      "Epoch 097: | Loss: 0.69322 | Acc: 70.549\n",
      "Epoch 098: | Loss: 0.69366 | Acc: 70.470\n",
      "Epoch 099: | Loss: 0.69368 | Acc: 70.468\n",
      "Epoch 100: | Loss: 0.69360 | Acc: 70.412\n"
     ]
    }
   ],
   "source": [
    "train_model_ternary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 71.0\n"
     ]
    }
   ],
   "source": [
    "test_model_ternary(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comments about this question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Word2Vec Model</th>\n",
       "      <th>Classification Type</th>\n",
       "      <th>Input Features Type</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FNN</td>\n",
       "      <td>Google News</td>\n",
       "      <td>Binary</td>\n",
       "      <td>Average</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FNN</td>\n",
       "      <td>Amazon Reviews(Our)</td>\n",
       "      <td>Binary</td>\n",
       "      <td>Average</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FNN</td>\n",
       "      <td>Google News</td>\n",
       "      <td>Ternary</td>\n",
       "      <td>Average</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FNN</td>\n",
       "      <td>Amazon Reviews(Our)</td>\n",
       "      <td>Ternary</td>\n",
       "      <td>Average</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model       Word2Vec Model Classification Type Input Features Type Accuracy\n",
       "0   FNN          Google News              Binary             Average     0.85\n",
       "1   FNN  Amazon Reviews(Our)              Binary             Average     0.87\n",
       "2   FNN          Google News             Ternary             Average     0.68\n",
       "3   FNN  Amazon Reviews(Our)             Ternary             Average     0.71"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'Model': ['FNN', 'FNN', 'FNN', 'FNN'], \n",
    "     'Word2Vec Model': ['Google News', 'Amazon Reviews(Our)', 'Google News', 'Amazon Reviews(Our)'],\n",
    "     'Classification Type': ['Binary', 'Binary', 'Ternary', 'Ternary',],\n",
    "     'Input Features Type': ['Average' , 'Average', 'Average', 'Average'],\n",
    "     'Accuracy': ['0.85', '0.87', '0.68', '0.71']}\n",
    "\n",
    "df_results_part_4_a = pd.DataFrame(data=d)\n",
    "df_results_part_4_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to pad a list with a specific number of zeroes\n",
    "\n",
    "def pad_or_truncate(some_list, target_len):\n",
    "    return some_list[:target_len] + [0]*(target_len - len(some_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to concatenate vectors of first ten words as your input feature \n",
    "\n",
    "def concatenate_vectors(review,model_used):\n",
    "\n",
    "    sentence_words = review.split(\" \")\n",
    "    \n",
    "    sentence_vectors = []    \n",
    "    \n",
    "    for i,word in enumerate(sentence_words):\n",
    "        if i < 10:\n",
    "            try:\n",
    "                sentence_vectors.append(model_used[word])\n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    flattened_sentence_vector = np.array(sentence_vectors).flatten()\n",
    "    \n",
    "    if len(sentence_vectors)!=0:\n",
    "        if len(flattened_sentence_vector) != 3000:\n",
    "            flattened_sentence_vector = pad_or_truncate(list(flattened_sentence_vector),3000)\n",
    "                \n",
    "        return flattened_sentence_vector\n",
    "\n",
    "    else:\n",
    "        return np.zeros(3000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "      <th>class</th>\n",
       "      <th>avg_input_features_1</th>\n",
       "      <th>avg_input_features_2</th>\n",
       "      <th>concat_input_features_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>assume four charger bought item pretty bought ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.04277208, -0.03597005, -0.062435575, 0.1046...</td>\n",
       "      <td>[0.017703589, -0.11186184, -0.0030522645, -0.0...</td>\n",
       "      <td>[0.06640625, -0.103027344, -0.08251953, 0.1079...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>son like cook he especially good grill burger ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.004893621, 0.029286703, -0.01199023, 0.162...</td>\n",
       "      <td>[0.120273024, -0.14361034, 0.046780374, -0.138...</td>\n",
       "      <td>[0.107910156, -0.030029297, 0.033203125, -0.16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ship fast good price way huger expect</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.1432408, 0.08569336, -0.048673358, 0.078264...</td>\n",
       "      <td>[-0.049596105, -0.018341891, 0.13302507, -0.17...</td>\n",
       "      <td>[0.27929688, 0.29101562, -0.21386719, -0.14648...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>container great lid thin break easily one use</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.056274414, 0.10064697, -0.0005340576, 0.056...</td>\n",
       "      <td>[0.030435072, -0.15327847, 0.11309578, -0.1425...</td>\n",
       "      <td>[0.048095703, 0.31640625, 0.17773438, -0.06982...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>item receive broken return ask replacement shi...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.043584187, -0.013412476, -0.116475426, 0.06...</td>\n",
       "      <td>[0.08915458, -0.22801971, -0.028520422, -0.263...</td>\n",
       "      <td>[0.024291992, 0.010803223, -0.107421875, 0.302...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249995</th>\n",
       "      <td>lock come easily hard clean top</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.03120931, 0.07987467, 0.03741455, 0.0357869...</td>\n",
       "      <td>[0.015699785, -0.12990652, 0.21889718, -0.1027...</td>\n",
       "      <td>[0.017944336, 0.19335938, -0.06298828, 0.02429...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249996</th>\n",
       "      <td>bum carafe slightly wide bit short metal struc...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.001551011, 0.026309744, -0.06418026, 0.125...</td>\n",
       "      <td>[0.015504825, -0.031771064, 0.1092756, -0.0557...</td>\n",
       "      <td>[0.10546875, -0.20117188, -0.13964844, 0.32226...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249997</th>\n",
       "      <td>I kettle one month leak water leak seal bottom...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0027923584, 0.092679344, -0.03684489, 0.028...</td>\n",
       "      <td>[0.020719932, -0.090553395, 0.13070571, -0.027...</td>\n",
       "      <td>[0.07910156, -0.0050354004, 0.111816406, 0.212...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249998</th>\n",
       "      <td>idea color balloon entice order package child ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.047094908, 0.011726828, 0.00012925093, 0.09...</td>\n",
       "      <td>[0.066825956, -0.17564225, 0.05628306, -0.0763...</td>\n",
       "      <td>[0.067871094, 0.011657715, 0.033691406, 0.2207...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249999</th>\n",
       "      <td>product fail almost immediately digit garble s...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.085134655, -0.011324369, 0.06199294, 0.0255...</td>\n",
       "      <td>[0.0051919767, -0.1441225, 0.13658296, -0.1857...</td>\n",
       "      <td>[-0.061523438, 0.095214844, 0.13378906, 0.0649...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review_body  class  \\\n",
       "0       assume four charger bought item pretty bought ...      1   \n",
       "1       son like cook he especially good grill burger ...      0   \n",
       "2                   ship fast good price way huger expect      0   \n",
       "3           container great lid thin break easily one use      2   \n",
       "4       item receive broken return ask replacement shi...      1   \n",
       "...                                                   ...    ...   \n",
       "249995                    lock come easily hard clean top      2   \n",
       "249996  bum carafe slightly wide bit short metal struc...      1   \n",
       "249997  I kettle one month leak water leak seal bottom...      1   \n",
       "249998  idea color balloon entice order package child ...      1   \n",
       "249999  product fail almost immediately digit garble s...      1   \n",
       "\n",
       "                                     avg_input_features_1  \\\n",
       "0       [0.04277208, -0.03597005, -0.062435575, 0.1046...   \n",
       "1       [-0.004893621, 0.029286703, -0.01199023, 0.162...   \n",
       "2       [0.1432408, 0.08569336, -0.048673358, 0.078264...   \n",
       "3       [0.056274414, 0.10064697, -0.0005340576, 0.056...   \n",
       "4       [0.043584187, -0.013412476, -0.116475426, 0.06...   \n",
       "...                                                   ...   \n",
       "249995  [0.03120931, 0.07987467, 0.03741455, 0.0357869...   \n",
       "249996  [-0.001551011, 0.026309744, -0.06418026, 0.125...   \n",
       "249997  [0.0027923584, 0.092679344, -0.03684489, 0.028...   \n",
       "249998  [0.047094908, 0.011726828, 0.00012925093, 0.09...   \n",
       "249999  [0.085134655, -0.011324369, 0.06199294, 0.0255...   \n",
       "\n",
       "                                     avg_input_features_2  \\\n",
       "0       [0.017703589, -0.11186184, -0.0030522645, -0.0...   \n",
       "1       [0.120273024, -0.14361034, 0.046780374, -0.138...   \n",
       "2       [-0.049596105, -0.018341891, 0.13302507, -0.17...   \n",
       "3       [0.030435072, -0.15327847, 0.11309578, -0.1425...   \n",
       "4       [0.08915458, -0.22801971, -0.028520422, -0.263...   \n",
       "...                                                   ...   \n",
       "249995  [0.015699785, -0.12990652, 0.21889718, -0.1027...   \n",
       "249996  [0.015504825, -0.031771064, 0.1092756, -0.0557...   \n",
       "249997  [0.020719932, -0.090553395, 0.13070571, -0.027...   \n",
       "249998  [0.066825956, -0.17564225, 0.05628306, -0.0763...   \n",
       "249999  [0.0051919767, -0.1441225, 0.13658296, -0.1857...   \n",
       "\n",
       "                                  concat_input_features_1  \n",
       "0       [0.06640625, -0.103027344, -0.08251953, 0.1079...  \n",
       "1       [0.107910156, -0.030029297, 0.033203125, -0.16...  \n",
       "2       [0.27929688, 0.29101562, -0.21386719, -0.14648...  \n",
       "3       [0.048095703, 0.31640625, 0.17773438, -0.06982...  \n",
       "4       [0.024291992, 0.010803223, -0.107421875, 0.302...  \n",
       "...                                                   ...  \n",
       "249995  [0.017944336, 0.19335938, -0.06298828, 0.02429...  \n",
       "249996  [0.10546875, -0.20117188, -0.13964844, 0.32226...  \n",
       "249997  [0.07910156, -0.0050354004, 0.111816406, 0.212...  \n",
       "249998  [0.067871094, 0.011657715, 0.033691406, 0.2207...  \n",
       "249999  [-0.061523438, 0.095214844, 0.13378906, 0.0649...  \n",
       "\n",
       "[250000 rows x 5 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find input feature for google model\n",
    "\n",
    "df_org_3['concat_input_features_1'] = df_org_3['review_body'].apply(lambda x: concatenate_vectors(x,wv))\n",
    "df_org_3    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-7c3efbd4463c>:12: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  sentence_vectors.append(model_used[word])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "      <th>class</th>\n",
       "      <th>avg_input_features_1</th>\n",
       "      <th>avg_input_features_2</th>\n",
       "      <th>concat_input_features_1</th>\n",
       "      <th>concat_input_features_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>assume four charger bought item pretty bought ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.04277208, -0.03597005, -0.062435575, 0.1046...</td>\n",
       "      <td>[0.017703589, -0.11186184, -0.0030522645, -0.0...</td>\n",
       "      <td>[0.06640625, -0.103027344, -0.08251953, 0.1079...</td>\n",
       "      <td>[0.18149155, -0.23886244, -0.0827184, 0.060127...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>son like cook he especially good grill burger ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.004893621, 0.029286703, -0.01199023, 0.162...</td>\n",
       "      <td>[0.120273024, -0.14361034, 0.046780374, -0.138...</td>\n",
       "      <td>[0.107910156, -0.030029297, 0.033203125, -0.16...</td>\n",
       "      <td>[0.39106262, -0.43970776, -0.014117015, 0.1198...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ship fast good price way huger expect</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.1432408, 0.08569336, -0.048673358, 0.078264...</td>\n",
       "      <td>[-0.049596105, -0.018341891, 0.13302507, -0.17...</td>\n",
       "      <td>[0.27929688, 0.29101562, -0.21386719, -0.14648...</td>\n",
       "      <td>[-0.07464662, -0.21261097, -0.26036084, -0.465...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>container great lid thin break easily one use</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.056274414, 0.10064697, -0.0005340576, 0.056...</td>\n",
       "      <td>[0.030435072, -0.15327847, 0.11309578, -0.1425...</td>\n",
       "      <td>[0.048095703, 0.31640625, 0.17773438, -0.06982...</td>\n",
       "      <td>[-0.044359308, -0.092595585, 0.07619203, -0.14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>item receive broken return ask replacement shi...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.043584187, -0.013412476, -0.116475426, 0.06...</td>\n",
       "      <td>[0.08915458, -0.22801971, -0.028520422, -0.263...</td>\n",
       "      <td>[0.024291992, 0.010803223, -0.107421875, 0.302...</td>\n",
       "      <td>[0.102800496, -0.12086469, -0.14640297, 0.0537...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249995</th>\n",
       "      <td>lock come easily hard clean top</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.03120931, 0.07987467, 0.03741455, 0.0357869...</td>\n",
       "      <td>[0.015699785, -0.12990652, 0.21889718, -0.1027...</td>\n",
       "      <td>[0.017944336, 0.19335938, -0.06298828, 0.02429...</td>\n",
       "      <td>[0.24208477, -0.24096622, 0.30787, -0.2916415,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249996</th>\n",
       "      <td>bum carafe slightly wide bit short metal struc...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.001551011, 0.026309744, -0.06418026, 0.125...</td>\n",
       "      <td>[0.015504825, -0.031771064, 0.1092756, -0.0557...</td>\n",
       "      <td>[0.10546875, -0.20117188, -0.13964844, 0.32226...</td>\n",
       "      <td>[0.14765103, -0.15398727, 0.014575721, -0.1541...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249997</th>\n",
       "      <td>I kettle one month leak water leak seal bottom...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0027923584, 0.092679344, -0.03684489, 0.028...</td>\n",
       "      <td>[0.020719932, -0.090553395, 0.13070571, -0.027...</td>\n",
       "      <td>[0.07910156, -0.0050354004, 0.111816406, 0.212...</td>\n",
       "      <td>[0.2060052, -0.18501587, -0.0031185225, -0.029...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249998</th>\n",
       "      <td>idea color balloon entice order package child ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.047094908, 0.011726828, 0.00012925093, 0.09...</td>\n",
       "      <td>[0.066825956, -0.17564225, 0.05628306, -0.0763...</td>\n",
       "      <td>[0.067871094, 0.011657715, 0.033691406, 0.2207...</td>\n",
       "      <td>[0.07186723, -0.11819719, -0.024285497, -0.130...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249999</th>\n",
       "      <td>product fail almost immediately digit garble s...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.085134655, -0.011324369, 0.06199294, 0.0255...</td>\n",
       "      <td>[0.0051919767, -0.1441225, 0.13658296, -0.1857...</td>\n",
       "      <td>[-0.061523438, 0.095214844, 0.13378906, 0.0649...</td>\n",
       "      <td>[0.17383887, 0.03144031, -0.15070951, -0.04374...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review_body  class  \\\n",
       "0       assume four charger bought item pretty bought ...      1   \n",
       "1       son like cook he especially good grill burger ...      0   \n",
       "2                   ship fast good price way huger expect      0   \n",
       "3           container great lid thin break easily one use      2   \n",
       "4       item receive broken return ask replacement shi...      1   \n",
       "...                                                   ...    ...   \n",
       "249995                    lock come easily hard clean top      2   \n",
       "249996  bum carafe slightly wide bit short metal struc...      1   \n",
       "249997  I kettle one month leak water leak seal bottom...      1   \n",
       "249998  idea color balloon entice order package child ...      1   \n",
       "249999  product fail almost immediately digit garble s...      1   \n",
       "\n",
       "                                     avg_input_features_1  \\\n",
       "0       [0.04277208, -0.03597005, -0.062435575, 0.1046...   \n",
       "1       [-0.004893621, 0.029286703, -0.01199023, 0.162...   \n",
       "2       [0.1432408, 0.08569336, -0.048673358, 0.078264...   \n",
       "3       [0.056274414, 0.10064697, -0.0005340576, 0.056...   \n",
       "4       [0.043584187, -0.013412476, -0.116475426, 0.06...   \n",
       "...                                                   ...   \n",
       "249995  [0.03120931, 0.07987467, 0.03741455, 0.0357869...   \n",
       "249996  [-0.001551011, 0.026309744, -0.06418026, 0.125...   \n",
       "249997  [0.0027923584, 0.092679344, -0.03684489, 0.028...   \n",
       "249998  [0.047094908, 0.011726828, 0.00012925093, 0.09...   \n",
       "249999  [0.085134655, -0.011324369, 0.06199294, 0.0255...   \n",
       "\n",
       "                                     avg_input_features_2  \\\n",
       "0       [0.017703589, -0.11186184, -0.0030522645, -0.0...   \n",
       "1       [0.120273024, -0.14361034, 0.046780374, -0.138...   \n",
       "2       [-0.049596105, -0.018341891, 0.13302507, -0.17...   \n",
       "3       [0.030435072, -0.15327847, 0.11309578, -0.1425...   \n",
       "4       [0.08915458, -0.22801971, -0.028520422, -0.263...   \n",
       "...                                                   ...   \n",
       "249995  [0.015699785, -0.12990652, 0.21889718, -0.1027...   \n",
       "249996  [0.015504825, -0.031771064, 0.1092756, -0.0557...   \n",
       "249997  [0.020719932, -0.090553395, 0.13070571, -0.027...   \n",
       "249998  [0.066825956, -0.17564225, 0.05628306, -0.0763...   \n",
       "249999  [0.0051919767, -0.1441225, 0.13658296, -0.1857...   \n",
       "\n",
       "                                  concat_input_features_1  \\\n",
       "0       [0.06640625, -0.103027344, -0.08251953, 0.1079...   \n",
       "1       [0.107910156, -0.030029297, 0.033203125, -0.16...   \n",
       "2       [0.27929688, 0.29101562, -0.21386719, -0.14648...   \n",
       "3       [0.048095703, 0.31640625, 0.17773438, -0.06982...   \n",
       "4       [0.024291992, 0.010803223, -0.107421875, 0.302...   \n",
       "...                                                   ...   \n",
       "249995  [0.017944336, 0.19335938, -0.06298828, 0.02429...   \n",
       "249996  [0.10546875, -0.20117188, -0.13964844, 0.32226...   \n",
       "249997  [0.07910156, -0.0050354004, 0.111816406, 0.212...   \n",
       "249998  [0.067871094, 0.011657715, 0.033691406, 0.2207...   \n",
       "249999  [-0.061523438, 0.095214844, 0.13378906, 0.0649...   \n",
       "\n",
       "                                  concat_input_features_2  \n",
       "0       [0.18149155, -0.23886244, -0.0827184, 0.060127...  \n",
       "1       [0.39106262, -0.43970776, -0.014117015, 0.1198...  \n",
       "2       [-0.07464662, -0.21261097, -0.26036084, -0.465...  \n",
       "3       [-0.044359308, -0.092595585, 0.07619203, -0.14...  \n",
       "4       [0.102800496, -0.12086469, -0.14640297, 0.0537...  \n",
       "...                                                   ...  \n",
       "249995  [0.24208477, -0.24096622, 0.30787, -0.2916415,...  \n",
       "249996  [0.14765103, -0.15398727, 0.014575721, -0.1541...  \n",
       "249997  [0.2060052, -0.18501587, -0.0031185225, -0.029...  \n",
       "249998  [0.07186723, -0.11819719, -0.024285497, -0.130...  \n",
       "249999  [0.17383887, 0.03144031, -0.15070951, -0.04374...  \n",
       "\n",
       "[250000 rows x 6 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find input feature for our model\n",
    "\n",
    "df_org_3['concat_input_features_2'] = df_org_3['review_body'].apply(lambda x: concatenate_vectors(x,final_model))\n",
    "df_org_3    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "      <th>class</th>\n",
       "      <th>avg_input_features_1</th>\n",
       "      <th>avg_input_features_2</th>\n",
       "      <th>concat_input_features_1</th>\n",
       "      <th>concat_input_features_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>assume four charger bought item pretty bought ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.04277208, -0.03597005, -0.062435575, 0.1046...</td>\n",
       "      <td>[0.017703589, -0.11186184, -0.0030522645, -0.0...</td>\n",
       "      <td>[0.06640625, -0.103027344, -0.08251953, 0.1079...</td>\n",
       "      <td>[0.18149155, -0.23886244, -0.0827184, 0.060127...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>son like cook he especially good grill burger ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.004893621, 0.029286703, -0.01199023, 0.162...</td>\n",
       "      <td>[0.120273024, -0.14361034, 0.046780374, -0.138...</td>\n",
       "      <td>[0.107910156, -0.030029297, 0.033203125, -0.16...</td>\n",
       "      <td>[0.39106262, -0.43970776, -0.014117015, 0.1198...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ship fast good price way huger expect</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.1432408, 0.08569336, -0.048673358, 0.078264...</td>\n",
       "      <td>[-0.049596105, -0.018341891, 0.13302507, -0.17...</td>\n",
       "      <td>[0.27929688, 0.29101562, -0.21386719, -0.14648...</td>\n",
       "      <td>[-0.07464662, -0.21261097, -0.26036084, -0.465...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>item receive broken return ask replacement shi...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.043584187, -0.013412476, -0.116475426, 0.06...</td>\n",
       "      <td>[0.08915458, -0.22801971, -0.028520422, -0.263...</td>\n",
       "      <td>[0.024291992, 0.010803223, -0.107421875, 0.302...</td>\n",
       "      <td>[0.102800496, -0.12086469, -0.14640297, 0.0537...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>experience issue one cup fill make sure filter...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0077209473, -0.015841166, -0.04876624, 0.11...</td>\n",
       "      <td>[0.0042549637, -0.026836593, 0.14918885, -0.08...</td>\n",
       "      <td>[0.037841797, -0.060058594, -0.05810547, -0.15...</td>\n",
       "      <td>[0.15096039, 0.03984432, 0.08405365, -0.053545...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249993</th>\n",
       "      <td>toaster oven fine especially since paid amazon...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.03401947, 0.05153087, -0.0007176717, 0.0253...</td>\n",
       "      <td>[0.050901376, -0.11194899, 0.12081799, -0.0080...</td>\n",
       "      <td>[0.14453125, -0.07421875, -0.043945312, 0.2382...</td>\n",
       "      <td>[0.28356823, 0.13480736, -0.103595145, 0.34340...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249996</th>\n",
       "      <td>bum carafe slightly wide bit short metal struc...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.001551011, 0.026309744, -0.06418026, 0.125...</td>\n",
       "      <td>[0.015504825, -0.031771064, 0.1092756, -0.0557...</td>\n",
       "      <td>[0.10546875, -0.20117188, -0.13964844, 0.32226...</td>\n",
       "      <td>[0.14765103, -0.15398727, 0.014575721, -0.1541...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249997</th>\n",
       "      <td>I kettle one month leak water leak seal bottom...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0027923584, 0.092679344, -0.03684489, 0.028...</td>\n",
       "      <td>[0.020719932, -0.090553395, 0.13070571, -0.027...</td>\n",
       "      <td>[0.07910156, -0.0050354004, 0.111816406, 0.212...</td>\n",
       "      <td>[0.2060052, -0.18501587, -0.0031185225, -0.029...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249998</th>\n",
       "      <td>idea color balloon entice order package child ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.047094908, 0.011726828, 0.00012925093, 0.09...</td>\n",
       "      <td>[0.066825956, -0.17564225, 0.05628306, -0.0763...</td>\n",
       "      <td>[0.067871094, 0.011657715, 0.033691406, 0.2207...</td>\n",
       "      <td>[0.07186723, -0.11819719, -0.024285497, -0.130...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249999</th>\n",
       "      <td>product fail almost immediately digit garble s...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.085134655, -0.011324369, 0.06199294, 0.0255...</td>\n",
       "      <td>[0.0051919767, -0.1441225, 0.13658296, -0.1857...</td>\n",
       "      <td>[-0.061523438, 0.095214844, 0.13378906, 0.0649...</td>\n",
       "      <td>[0.17383887, 0.03144031, -0.15070951, -0.04374...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review_body  class  \\\n",
       "0       assume four charger bought item pretty bought ...      1   \n",
       "1       son like cook he especially good grill burger ...      0   \n",
       "2                   ship fast good price way huger expect      0   \n",
       "4       item receive broken return ask replacement shi...      1   \n",
       "5       experience issue one cup fill make sure filter...      0   \n",
       "...                                                   ...    ...   \n",
       "249993  toaster oven fine especially since paid amazon...      1   \n",
       "249996  bum carafe slightly wide bit short metal struc...      1   \n",
       "249997  I kettle one month leak water leak seal bottom...      1   \n",
       "249998  idea color balloon entice order package child ...      1   \n",
       "249999  product fail almost immediately digit garble s...      1   \n",
       "\n",
       "                                     avg_input_features_1  \\\n",
       "0       [0.04277208, -0.03597005, -0.062435575, 0.1046...   \n",
       "1       [-0.004893621, 0.029286703, -0.01199023, 0.162...   \n",
       "2       [0.1432408, 0.08569336, -0.048673358, 0.078264...   \n",
       "4       [0.043584187, -0.013412476, -0.116475426, 0.06...   \n",
       "5       [0.0077209473, -0.015841166, -0.04876624, 0.11...   \n",
       "...                                                   ...   \n",
       "249993  [0.03401947, 0.05153087, -0.0007176717, 0.0253...   \n",
       "249996  [-0.001551011, 0.026309744, -0.06418026, 0.125...   \n",
       "249997  [0.0027923584, 0.092679344, -0.03684489, 0.028...   \n",
       "249998  [0.047094908, 0.011726828, 0.00012925093, 0.09...   \n",
       "249999  [0.085134655, -0.011324369, 0.06199294, 0.0255...   \n",
       "\n",
       "                                     avg_input_features_2  \\\n",
       "0       [0.017703589, -0.11186184, -0.0030522645, -0.0...   \n",
       "1       [0.120273024, -0.14361034, 0.046780374, -0.138...   \n",
       "2       [-0.049596105, -0.018341891, 0.13302507, -0.17...   \n",
       "4       [0.08915458, -0.22801971, -0.028520422, -0.263...   \n",
       "5       [0.0042549637, -0.026836593, 0.14918885, -0.08...   \n",
       "...                                                   ...   \n",
       "249993  [0.050901376, -0.11194899, 0.12081799, -0.0080...   \n",
       "249996  [0.015504825, -0.031771064, 0.1092756, -0.0557...   \n",
       "249997  [0.020719932, -0.090553395, 0.13070571, -0.027...   \n",
       "249998  [0.066825956, -0.17564225, 0.05628306, -0.0763...   \n",
       "249999  [0.0051919767, -0.1441225, 0.13658296, -0.1857...   \n",
       "\n",
       "                                  concat_input_features_1  \\\n",
       "0       [0.06640625, -0.103027344, -0.08251953, 0.1079...   \n",
       "1       [0.107910156, -0.030029297, 0.033203125, -0.16...   \n",
       "2       [0.27929688, 0.29101562, -0.21386719, -0.14648...   \n",
       "4       [0.024291992, 0.010803223, -0.107421875, 0.302...   \n",
       "5       [0.037841797, -0.060058594, -0.05810547, -0.15...   \n",
       "...                                                   ...   \n",
       "249993  [0.14453125, -0.07421875, -0.043945312, 0.2382...   \n",
       "249996  [0.10546875, -0.20117188, -0.13964844, 0.32226...   \n",
       "249997  [0.07910156, -0.0050354004, 0.111816406, 0.212...   \n",
       "249998  [0.067871094, 0.011657715, 0.033691406, 0.2207...   \n",
       "249999  [-0.061523438, 0.095214844, 0.13378906, 0.0649...   \n",
       "\n",
       "                                  concat_input_features_2  \n",
       "0       [0.18149155, -0.23886244, -0.0827184, 0.060127...  \n",
       "1       [0.39106262, -0.43970776, -0.014117015, 0.1198...  \n",
       "2       [-0.07464662, -0.21261097, -0.26036084, -0.465...  \n",
       "4       [0.102800496, -0.12086469, -0.14640297, 0.0537...  \n",
       "5       [0.15096039, 0.03984432, 0.08405365, -0.053545...  \n",
       "...                                                   ...  \n",
       "249993  [0.28356823, 0.13480736, -0.103595145, 0.34340...  \n",
       "249996  [0.14765103, -0.15398727, 0.014575721, -0.1541...  \n",
       "249997  [0.2060052, -0.18501587, -0.0031185225, -0.029...  \n",
       "249998  [0.07186723, -0.11819719, -0.024285497, -0.130...  \n",
       "249999  [0.17383887, 0.03144031, -0.15070951, -0.04374...  \n",
       "\n",
       "[200000 rows x 6 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# binary classification dataframe\n",
    "\n",
    "df_binary = df_org_3[((df_org_3['class'] == 0) | (df_org_3['class'] == 1))]\n",
    "df_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters \n",
    "\n",
    "input_size = 3000\n",
    "hidden_1_size = 50\n",
    "hidden_2_size = 10\n",
    "output_size = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_binary['concat_input_features_1']\n",
    "y = df_binary['class']\n",
    "\n",
    "# Split the dataset into 80% training dataset and 20% testing dataset\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train data\n",
    "train_data = trainData(torch.FloatTensor(x_train.tolist()), \n",
    "                       torch.FloatTensor(y_train))\n",
    "## test data    \n",
    "test_data = testData(torch.FloatTensor(x_test.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_classification(\n",
      "  (layer_1): Linear(in_features=3000, out_features=50, bias=True)\n",
      "  (layer_2): Linear(in_features=50, out_features=10, bias=True)\n",
      "  (layer_out): Linear(in_features=10, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (batchnorm1): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm2): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# print model\n",
    "\n",
    "model = binary_classification()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function and optimizer\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Loss: 0.51775 | Acc: 74.389\n",
      "Epoch 002: | Loss: 0.48779 | Acc: 76.416\n",
      "Epoch 003: | Loss: 0.46733 | Acc: 77.754\n",
      "Epoch 004: | Loss: 0.45035 | Acc: 78.726\n",
      "Epoch 005: | Loss: 0.43386 | Acc: 79.877\n",
      "Epoch 006: | Loss: 0.41914 | Acc: 80.656\n",
      "Epoch 007: | Loss: 0.40263 | Acc: 81.550\n",
      "Epoch 008: | Loss: 0.39206 | Acc: 82.135\n",
      "Epoch 009: | Loss: 0.37960 | Acc: 82.766\n",
      "Epoch 010: | Loss: 0.36853 | Acc: 83.453\n",
      "Epoch 011: | Loss: 0.35869 | Acc: 83.838\n",
      "Epoch 012: | Loss: 0.34956 | Acc: 84.293\n",
      "Epoch 013: | Loss: 0.34203 | Acc: 84.739\n",
      "Epoch 014: | Loss: 0.33421 | Acc: 85.152\n",
      "Epoch 015: | Loss: 0.32706 | Acc: 85.552\n",
      "Epoch 016: | Loss: 0.31937 | Acc: 85.869\n",
      "Epoch 017: | Loss: 0.31509 | Acc: 86.163\n",
      "Epoch 018: | Loss: 0.30826 | Acc: 86.475\n",
      "Epoch 019: | Loss: 0.30178 | Acc: 86.912\n",
      "Epoch 020: | Loss: 0.29440 | Acc: 87.188\n",
      "Epoch 021: | Loss: 0.29068 | Acc: 87.469\n",
      "Epoch 022: | Loss: 0.28397 | Acc: 87.698\n",
      "Epoch 023: | Loss: 0.27952 | Acc: 88.007\n",
      "Epoch 024: | Loss: 0.27510 | Acc: 88.255\n",
      "Epoch 025: | Loss: 0.27316 | Acc: 88.382\n",
      "Epoch 026: | Loss: 0.26708 | Acc: 88.584\n",
      "Epoch 027: | Loss: 0.26345 | Acc: 88.776\n",
      "Epoch 028: | Loss: 0.26083 | Acc: 88.868\n",
      "Epoch 029: | Loss: 0.25491 | Acc: 89.221\n",
      "Epoch 030: | Loss: 0.25360 | Acc: 89.345\n",
      "Epoch 031: | Loss: 0.24915 | Acc: 89.467\n",
      "Epoch 032: | Loss: 0.24396 | Acc: 89.727\n",
      "Epoch 033: | Loss: 0.24337 | Acc: 89.830\n",
      "Epoch 034: | Loss: 0.24063 | Acc: 89.904\n",
      "Epoch 035: | Loss: 0.23791 | Acc: 90.053\n",
      "Epoch 036: | Loss: 0.23743 | Acc: 90.127\n",
      "Epoch 037: | Loss: 0.23167 | Acc: 90.332\n",
      "Epoch 038: | Loss: 0.23147 | Acc: 90.436\n",
      "Epoch 039: | Loss: 0.22834 | Acc: 90.511\n",
      "Epoch 040: | Loss: 0.22583 | Acc: 90.581\n",
      "Epoch 041: | Loss: 0.22392 | Acc: 90.703\n",
      "Epoch 042: | Loss: 0.22017 | Acc: 90.826\n",
      "Epoch 043: | Loss: 0.21828 | Acc: 90.966\n",
      "Epoch 044: | Loss: 0.21565 | Acc: 91.126\n",
      "Epoch 045: | Loss: 0.21212 | Acc: 91.270\n",
      "Epoch 046: | Loss: 0.21202 | Acc: 91.290\n",
      "Epoch 047: | Loss: 0.21045 | Acc: 91.366\n",
      "Epoch 048: | Loss: 0.20793 | Acc: 91.474\n",
      "Epoch 049: | Loss: 0.20676 | Acc: 91.513\n",
      "Epoch 050: | Loss: 0.20067 | Acc: 91.831\n",
      "Epoch 051: | Loss: 0.20422 | Acc: 91.692\n",
      "Epoch 052: | Loss: 0.20268 | Acc: 91.831\n",
      "Epoch 053: | Loss: 0.19838 | Acc: 91.938\n",
      "Epoch 054: | Loss: 0.19680 | Acc: 91.986\n",
      "Epoch 055: | Loss: 0.19702 | Acc: 92.025\n",
      "Epoch 056: | Loss: 0.19391 | Acc: 92.185\n",
      "Epoch 057: | Loss: 0.19374 | Acc: 92.161\n",
      "Epoch 058: | Loss: 0.19349 | Acc: 92.219\n",
      "Epoch 059: | Loss: 0.19197 | Acc: 92.248\n",
      "Epoch 060: | Loss: 0.19062 | Acc: 92.291\n",
      "Epoch 061: | Loss: 0.18636 | Acc: 92.478\n",
      "Epoch 062: | Loss: 0.18559 | Acc: 92.550\n",
      "Epoch 063: | Loss: 0.18263 | Acc: 92.637\n",
      "Epoch 064: | Loss: 0.18395 | Acc: 92.572\n",
      "Epoch 065: | Loss: 0.18240 | Acc: 92.689\n",
      "Epoch 066: | Loss: 0.18033 | Acc: 92.797\n",
      "Epoch 067: | Loss: 0.17867 | Acc: 92.818\n",
      "Epoch 068: | Loss: 0.17821 | Acc: 92.855\n",
      "Epoch 069: | Loss: 0.17768 | Acc: 92.845\n",
      "Epoch 070: | Loss: 0.17720 | Acc: 92.916\n",
      "Epoch 071: | Loss: 0.17591 | Acc: 93.016\n",
      "Epoch 072: | Loss: 0.17262 | Acc: 93.171\n",
      "Epoch 073: | Loss: 0.17319 | Acc: 93.066\n",
      "Epoch 074: | Loss: 0.17144 | Acc: 93.142\n",
      "Epoch 075: | Loss: 0.17292 | Acc: 93.126\n",
      "Epoch 076: | Loss: 0.17108 | Acc: 93.180\n",
      "Epoch 077: | Loss: 0.17008 | Acc: 93.266\n",
      "Epoch 078: | Loss: 0.16747 | Acc: 93.394\n",
      "Epoch 079: | Loss: 0.16930 | Acc: 93.291\n",
      "Epoch 080: | Loss: 0.17138 | Acc: 93.216\n",
      "Epoch 081: | Loss: 0.16733 | Acc: 93.356\n",
      "Epoch 082: | Loss: 0.16468 | Acc: 93.520\n",
      "Epoch 083: | Loss: 0.16301 | Acc: 93.583\n",
      "Epoch 084: | Loss: 0.16332 | Acc: 93.579\n",
      "Epoch 085: | Loss: 0.16133 | Acc: 93.643\n",
      "Epoch 086: | Loss: 0.16073 | Acc: 93.674\n",
      "Epoch 087: | Loss: 0.16171 | Acc: 93.589\n",
      "Epoch 088: | Loss: 0.15998 | Acc: 93.707\n",
      "Epoch 089: | Loss: 0.15461 | Acc: 93.942\n",
      "Epoch 090: | Loss: 0.15761 | Acc: 93.778\n",
      "Epoch 091: | Loss: 0.15520 | Acc: 93.917\n",
      "Epoch 092: | Loss: 0.15874 | Acc: 93.737\n",
      "Epoch 093: | Loss: 0.15490 | Acc: 93.859\n",
      "Epoch 094: | Loss: 0.15726 | Acc: 93.867\n",
      "Epoch 095: | Loss: 0.15412 | Acc: 93.957\n",
      "Epoch 096: | Loss: 0.15527 | Acc: 93.920\n",
      "Epoch 097: | Loss: 0.15266 | Acc: 94.091\n",
      "Epoch 098: | Loss: 0.15011 | Acc: 94.139\n",
      "Epoch 099: | Loss: 0.15298 | Acc: 94.015\n",
      "Epoch 100: | Loss: 0.15289 | Acc: 94.037\n"
     ]
    }
   ],
   "source": [
    "train_model_binary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 73.0\n"
     ]
    }
   ],
   "source": [
    "test_model_binary(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_binary['concat_input_features_2']\n",
    "y = df_binary['class']\n",
    "\n",
    "# Split the dataset into 80% training dataset and 20% testing dataset\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train data\n",
    "train_data = trainData(torch.FloatTensor(x_train.tolist()), \n",
    "                       torch.FloatTensor(y_train))\n",
    "## test data    \n",
    "test_data = testData(torch.FloatTensor(x_test.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Loss: 0.52392 | Acc: 74.279\n",
      "Epoch 002: | Loss: 0.46477 | Acc: 77.858\n",
      "Epoch 003: | Loss: 0.45286 | Acc: 78.440\n",
      "Epoch 004: | Loss: 0.44242 | Acc: 79.154\n",
      "Epoch 005: | Loss: 0.42896 | Acc: 79.806\n",
      "Epoch 006: | Loss: 0.41631 | Acc: 80.604\n",
      "Epoch 007: | Loss: 0.40414 | Acc: 81.266\n",
      "Epoch 008: | Loss: 0.39191 | Acc: 81.942\n",
      "Epoch 009: | Loss: 0.37769 | Acc: 82.774\n",
      "Epoch 010: | Loss: 0.36850 | Acc: 83.203\n",
      "Epoch 011: | Loss: 0.35949 | Acc: 83.771\n",
      "Epoch 012: | Loss: 0.34855 | Acc: 84.371\n",
      "Epoch 013: | Loss: 0.33820 | Acc: 84.924\n",
      "Epoch 014: | Loss: 0.33224 | Acc: 85.205\n",
      "Epoch 015: | Loss: 0.32233 | Acc: 85.711\n",
      "Epoch 016: | Loss: 0.31424 | Acc: 86.075\n",
      "Epoch 017: | Loss: 0.30655 | Acc: 86.567\n",
      "Epoch 018: | Loss: 0.30080 | Acc: 86.804\n",
      "Epoch 019: | Loss: 0.29432 | Acc: 87.156\n",
      "Epoch 020: | Loss: 0.28855 | Acc: 87.446\n",
      "Epoch 021: | Loss: 0.28392 | Acc: 87.642\n",
      "Epoch 022: | Loss: 0.27764 | Acc: 87.976\n",
      "Epoch 023: | Loss: 0.27157 | Acc: 88.361\n",
      "Epoch 024: | Loss: 0.26821 | Acc: 88.508\n",
      "Epoch 025: | Loss: 0.26392 | Acc: 88.649\n",
      "Epoch 026: | Loss: 0.25885 | Acc: 88.853\n",
      "Epoch 027: | Loss: 0.25466 | Acc: 89.076\n",
      "Epoch 028: | Loss: 0.25365 | Acc: 89.181\n",
      "Epoch 029: | Loss: 0.24837 | Acc: 89.466\n",
      "Epoch 030: | Loss: 0.24390 | Acc: 89.680\n",
      "Epoch 031: | Loss: 0.23868 | Acc: 89.868\n",
      "Epoch 032: | Loss: 0.23578 | Acc: 90.108\n",
      "Epoch 033: | Loss: 0.23380 | Acc: 90.110\n",
      "Epoch 034: | Loss: 0.22838 | Acc: 90.402\n",
      "Epoch 035: | Loss: 0.22560 | Acc: 90.534\n",
      "Epoch 036: | Loss: 0.22524 | Acc: 90.596\n",
      "Epoch 037: | Loss: 0.22083 | Acc: 90.766\n",
      "Epoch 038: | Loss: 0.21918 | Acc: 90.830\n",
      "Epoch 039: | Loss: 0.21701 | Acc: 90.969\n",
      "Epoch 040: | Loss: 0.21415 | Acc: 91.147\n",
      "Epoch 041: | Loss: 0.21191 | Acc: 91.179\n",
      "Epoch 042: | Loss: 0.20940 | Acc: 91.334\n",
      "Epoch 043: | Loss: 0.20898 | Acc: 91.418\n",
      "Epoch 044: | Loss: 0.20536 | Acc: 91.519\n",
      "Epoch 045: | Loss: 0.20234 | Acc: 91.659\n",
      "Epoch 046: | Loss: 0.20109 | Acc: 91.770\n",
      "Epoch 047: | Loss: 0.20039 | Acc: 91.786\n",
      "Epoch 048: | Loss: 0.19649 | Acc: 91.987\n",
      "Epoch 049: | Loss: 0.19486 | Acc: 92.126\n",
      "Epoch 050: | Loss: 0.19592 | Acc: 91.933\n",
      "Epoch 051: | Loss: 0.19143 | Acc: 92.219\n",
      "Epoch 052: | Loss: 0.18970 | Acc: 92.348\n",
      "Epoch 053: | Loss: 0.18813 | Acc: 92.352\n",
      "Epoch 054: | Loss: 0.18709 | Acc: 92.403\n",
      "Epoch 055: | Loss: 0.18553 | Acc: 92.527\n",
      "Epoch 056: | Loss: 0.18574 | Acc: 92.422\n",
      "Epoch 057: | Loss: 0.18404 | Acc: 92.596\n",
      "Epoch 058: | Loss: 0.18102 | Acc: 92.691\n",
      "Epoch 059: | Loss: 0.17956 | Acc: 92.779\n",
      "Epoch 060: | Loss: 0.17721 | Acc: 92.861\n",
      "Epoch 061: | Loss: 0.17563 | Acc: 92.989\n",
      "Epoch 062: | Loss: 0.17797 | Acc: 92.803\n",
      "Epoch 063: | Loss: 0.17562 | Acc: 92.955\n",
      "Epoch 064: | Loss: 0.16973 | Acc: 93.213\n",
      "Epoch 065: | Loss: 0.17218 | Acc: 93.116\n",
      "Epoch 066: | Loss: 0.17179 | Acc: 93.054\n",
      "Epoch 067: | Loss: 0.16945 | Acc: 93.289\n",
      "Epoch 068: | Loss: 0.16897 | Acc: 93.194\n",
      "Epoch 069: | Loss: 0.16599 | Acc: 93.335\n",
      "Epoch 070: | Loss: 0.16764 | Acc: 93.335\n",
      "Epoch 071: | Loss: 0.16726 | Acc: 93.421\n",
      "Epoch 072: | Loss: 0.16422 | Acc: 93.443\n",
      "Epoch 073: | Loss: 0.16392 | Acc: 93.451\n",
      "Epoch 074: | Loss: 0.16250 | Acc: 93.578\n",
      "Epoch 075: | Loss: 0.16122 | Acc: 93.566\n",
      "Epoch 076: | Loss: 0.15902 | Acc: 93.722\n",
      "Epoch 077: | Loss: 0.15962 | Acc: 93.664\n",
      "Epoch 078: | Loss: 0.15592 | Acc: 93.852\n",
      "Epoch 079: | Loss: 0.15888 | Acc: 93.730\n",
      "Epoch 080: | Loss: 0.15686 | Acc: 93.798\n",
      "Epoch 081: | Loss: 0.15381 | Acc: 93.912\n",
      "Epoch 082: | Loss: 0.15526 | Acc: 93.907\n",
      "Epoch 083: | Loss: 0.15428 | Acc: 93.912\n",
      "Epoch 084: | Loss: 0.15345 | Acc: 93.929\n",
      "Epoch 085: | Loss: 0.14975 | Acc: 94.069\n",
      "Epoch 086: | Loss: 0.15242 | Acc: 94.016\n",
      "Epoch 087: | Loss: 0.15183 | Acc: 94.072\n",
      "Epoch 088: | Loss: 0.15024 | Acc: 94.066\n",
      "Epoch 089: | Loss: 0.15098 | Acc: 94.114\n",
      "Epoch 090: | Loss: 0.14866 | Acc: 94.149\n",
      "Epoch 091: | Loss: 0.15012 | Acc: 94.067\n",
      "Epoch 092: | Loss: 0.14592 | Acc: 94.261\n",
      "Epoch 093: | Loss: 0.14947 | Acc: 94.131\n",
      "Epoch 094: | Loss: 0.14673 | Acc: 94.283\n",
      "Epoch 095: | Loss: 0.14571 | Acc: 94.312\n",
      "Epoch 096: | Loss: 0.14395 | Acc: 94.397\n",
      "Epoch 097: | Loss: 0.14283 | Acc: 94.391\n",
      "Epoch 098: | Loss: 0.14514 | Acc: 94.362\n",
      "Epoch 099: | Loss: 0.14141 | Acc: 94.493\n",
      "Epoch 100: | Loss: 0.14172 | Acc: 94.451\n"
     ]
    }
   ],
   "source": [
    "train_model_binary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 75.0\n"
     ]
    }
   ],
   "source": [
    "test_model_binary(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ternary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "      <th>class</th>\n",
       "      <th>avg_input_features_1</th>\n",
       "      <th>avg_input_features_2</th>\n",
       "      <th>concat_input_features_1</th>\n",
       "      <th>concat_input_features_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>assume four charger bought item pretty bought ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.04277208, -0.03597005, -0.062435575, 0.1046...</td>\n",
       "      <td>[0.017703589, -0.11186184, -0.0030522645, -0.0...</td>\n",
       "      <td>[0.06640625, -0.103027344, -0.08251953, 0.1079...</td>\n",
       "      <td>[0.18149155, -0.23886244, -0.0827184, 0.060127...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>son like cook he especially good grill burger ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.004893621, 0.029286703, -0.01199023, 0.162...</td>\n",
       "      <td>[0.120273024, -0.14361034, 0.046780374, -0.138...</td>\n",
       "      <td>[0.107910156, -0.030029297, 0.033203125, -0.16...</td>\n",
       "      <td>[0.39106262, -0.43970776, -0.014117015, 0.1198...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ship fast good price way huger expect</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.1432408, 0.08569336, -0.048673358, 0.078264...</td>\n",
       "      <td>[-0.049596105, -0.018341891, 0.13302507, -0.17...</td>\n",
       "      <td>[0.27929688, 0.29101562, -0.21386719, -0.14648...</td>\n",
       "      <td>[-0.07464662, -0.21261097, -0.26036084, -0.465...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>container great lid thin break easily one use</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.056274414, 0.10064697, -0.0005340576, 0.056...</td>\n",
       "      <td>[0.030435072, -0.15327847, 0.11309578, -0.1425...</td>\n",
       "      <td>[0.048095703, 0.31640625, 0.17773438, -0.06982...</td>\n",
       "      <td>[-0.044359308, -0.092595585, 0.07619203, -0.14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>item receive broken return ask replacement shi...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.043584187, -0.013412476, -0.116475426, 0.06...</td>\n",
       "      <td>[0.08915458, -0.22801971, -0.028520422, -0.263...</td>\n",
       "      <td>[0.024291992, 0.010803223, -0.107421875, 0.302...</td>\n",
       "      <td>[0.102800496, -0.12086469, -0.14640297, 0.0537...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249995</th>\n",
       "      <td>lock come easily hard clean top</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.03120931, 0.07987467, 0.03741455, 0.0357869...</td>\n",
       "      <td>[0.015699785, -0.12990652, 0.21889718, -0.1027...</td>\n",
       "      <td>[0.017944336, 0.19335938, -0.06298828, 0.02429...</td>\n",
       "      <td>[0.24208477, -0.24096622, 0.30787, -0.2916415,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249996</th>\n",
       "      <td>bum carafe slightly wide bit short metal struc...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.001551011, 0.026309744, -0.06418026, 0.125...</td>\n",
       "      <td>[0.015504825, -0.031771064, 0.1092756, -0.0557...</td>\n",
       "      <td>[0.10546875, -0.20117188, -0.13964844, 0.32226...</td>\n",
       "      <td>[0.14765103, -0.15398727, 0.014575721, -0.1541...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249997</th>\n",
       "      <td>I kettle one month leak water leak seal bottom...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0027923584, 0.092679344, -0.03684489, 0.028...</td>\n",
       "      <td>[0.020719932, -0.090553395, 0.13070571, -0.027...</td>\n",
       "      <td>[0.07910156, -0.0050354004, 0.111816406, 0.212...</td>\n",
       "      <td>[0.2060052, -0.18501587, -0.0031185225, -0.029...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249998</th>\n",
       "      <td>idea color balloon entice order package child ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.047094908, 0.011726828, 0.00012925093, 0.09...</td>\n",
       "      <td>[0.066825956, -0.17564225, 0.05628306, -0.0763...</td>\n",
       "      <td>[0.067871094, 0.011657715, 0.033691406, 0.2207...</td>\n",
       "      <td>[0.07186723, -0.11819719, -0.024285497, -0.130...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249999</th>\n",
       "      <td>product fail almost immediately digit garble s...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.085134655, -0.011324369, 0.06199294, 0.0255...</td>\n",
       "      <td>[0.0051919767, -0.1441225, 0.13658296, -0.1857...</td>\n",
       "      <td>[-0.061523438, 0.095214844, 0.13378906, 0.0649...</td>\n",
       "      <td>[0.17383887, 0.03144031, -0.15070951, -0.04374...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review_body  class  \\\n",
       "0       assume four charger bought item pretty bought ...      1   \n",
       "1       son like cook he especially good grill burger ...      0   \n",
       "2                   ship fast good price way huger expect      0   \n",
       "3           container great lid thin break easily one use      2   \n",
       "4       item receive broken return ask replacement shi...      1   \n",
       "...                                                   ...    ...   \n",
       "249995                    lock come easily hard clean top      2   \n",
       "249996  bum carafe slightly wide bit short metal struc...      1   \n",
       "249997  I kettle one month leak water leak seal bottom...      1   \n",
       "249998  idea color balloon entice order package child ...      1   \n",
       "249999  product fail almost immediately digit garble s...      1   \n",
       "\n",
       "                                     avg_input_features_1  \\\n",
       "0       [0.04277208, -0.03597005, -0.062435575, 0.1046...   \n",
       "1       [-0.004893621, 0.029286703, -0.01199023, 0.162...   \n",
       "2       [0.1432408, 0.08569336, -0.048673358, 0.078264...   \n",
       "3       [0.056274414, 0.10064697, -0.0005340576, 0.056...   \n",
       "4       [0.043584187, -0.013412476, -0.116475426, 0.06...   \n",
       "...                                                   ...   \n",
       "249995  [0.03120931, 0.07987467, 0.03741455, 0.0357869...   \n",
       "249996  [-0.001551011, 0.026309744, -0.06418026, 0.125...   \n",
       "249997  [0.0027923584, 0.092679344, -0.03684489, 0.028...   \n",
       "249998  [0.047094908, 0.011726828, 0.00012925093, 0.09...   \n",
       "249999  [0.085134655, -0.011324369, 0.06199294, 0.0255...   \n",
       "\n",
       "                                     avg_input_features_2  \\\n",
       "0       [0.017703589, -0.11186184, -0.0030522645, -0.0...   \n",
       "1       [0.120273024, -0.14361034, 0.046780374, -0.138...   \n",
       "2       [-0.049596105, -0.018341891, 0.13302507, -0.17...   \n",
       "3       [0.030435072, -0.15327847, 0.11309578, -0.1425...   \n",
       "4       [0.08915458, -0.22801971, -0.028520422, -0.263...   \n",
       "...                                                   ...   \n",
       "249995  [0.015699785, -0.12990652, 0.21889718, -0.1027...   \n",
       "249996  [0.015504825, -0.031771064, 0.1092756, -0.0557...   \n",
       "249997  [0.020719932, -0.090553395, 0.13070571, -0.027...   \n",
       "249998  [0.066825956, -0.17564225, 0.05628306, -0.0763...   \n",
       "249999  [0.0051919767, -0.1441225, 0.13658296, -0.1857...   \n",
       "\n",
       "                                  concat_input_features_1  \\\n",
       "0       [0.06640625, -0.103027344, -0.08251953, 0.1079...   \n",
       "1       [0.107910156, -0.030029297, 0.033203125, -0.16...   \n",
       "2       [0.27929688, 0.29101562, -0.21386719, -0.14648...   \n",
       "3       [0.048095703, 0.31640625, 0.17773438, -0.06982...   \n",
       "4       [0.024291992, 0.010803223, -0.107421875, 0.302...   \n",
       "...                                                   ...   \n",
       "249995  [0.017944336, 0.19335938, -0.06298828, 0.02429...   \n",
       "249996  [0.10546875, -0.20117188, -0.13964844, 0.32226...   \n",
       "249997  [0.07910156, -0.0050354004, 0.111816406, 0.212...   \n",
       "249998  [0.067871094, 0.011657715, 0.033691406, 0.2207...   \n",
       "249999  [-0.061523438, 0.095214844, 0.13378906, 0.0649...   \n",
       "\n",
       "                                  concat_input_features_2  \n",
       "0       [0.18149155, -0.23886244, -0.0827184, 0.060127...  \n",
       "1       [0.39106262, -0.43970776, -0.014117015, 0.1198...  \n",
       "2       [-0.07464662, -0.21261097, -0.26036084, -0.465...  \n",
       "3       [-0.044359308, -0.092595585, 0.07619203, -0.14...  \n",
       "4       [0.102800496, -0.12086469, -0.14640297, 0.0537...  \n",
       "...                                                   ...  \n",
       "249995  [0.24208477, -0.24096622, 0.30787, -0.2916415,...  \n",
       "249996  [0.14765103, -0.15398727, 0.014575721, -0.1541...  \n",
       "249997  [0.2060052, -0.18501587, -0.0031185225, -0.029...  \n",
       "249998  [0.07186723, -0.11819719, -0.024285497, -0.130...  \n",
       "249999  [0.17383887, 0.03144031, -0.15070951, -0.04374...  \n",
       "\n",
       "[250000 rows x 6 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ternary classification dataframe\n",
    "\n",
    "df_ternary = df_org_3.copy(deep=True)\n",
    "df_ternary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters \n",
    "\n",
    "input_size = 3000\n",
    "hidden_1_size = 50\n",
    "hidden_2_size = 10\n",
    "output_size = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_ternary['concat_input_features_1']\n",
    "y = df_ternary['class']\n",
    "\n",
    "# Split the dataset into 80% training dataset and 20% testing dataset\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train data\n",
    "train_data = trainData(torch.FloatTensor(x_train.tolist()), \n",
    "                       torch.FloatTensor(y_train))\n",
    "## test data    \n",
    "test_data = testData(torch.FloatTensor(x_test.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ternary_classification(\n",
      "  (layer_1): Linear(in_features=3000, out_features=50, bias=True)\n",
      "  (layer_2): Linear(in_features=50, out_features=10, bias=True)\n",
      "  (layer_out): Linear(in_features=10, out_features=3, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (batchnorm1): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm2): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# print model\n",
    "\n",
    "model = ternary_classification()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function and optimizer\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Loss: 0.89409 | Acc: 59.612\n",
      "Epoch 002: | Loss: 0.86054 | Acc: 61.697\n",
      "Epoch 003: | Loss: 0.84039 | Acc: 62.864\n",
      "Epoch 004: | Loss: 0.82043 | Acc: 64.089\n",
      "Epoch 005: | Loss: 0.80407 | Acc: 64.951\n",
      "Epoch 006: | Loss: 0.78953 | Acc: 65.698\n",
      "Epoch 007: | Loss: 0.77770 | Acc: 66.365\n",
      "Epoch 008: | Loss: 0.76451 | Acc: 67.052\n",
      "Epoch 009: | Loss: 0.75307 | Acc: 67.719\n",
      "Epoch 010: | Loss: 0.73976 | Acc: 68.380\n",
      "Epoch 011: | Loss: 0.73238 | Acc: 68.749\n",
      "Epoch 012: | Loss: 0.72255 | Acc: 69.247\n",
      "Epoch 013: | Loss: 0.71186 | Acc: 69.825\n",
      "Epoch 014: | Loss: 0.70388 | Acc: 70.320\n",
      "Epoch 015: | Loss: 0.69564 | Acc: 70.564\n",
      "Epoch 016: | Loss: 0.68788 | Acc: 71.011\n",
      "Epoch 017: | Loss: 0.68257 | Acc: 71.261\n",
      "Epoch 018: | Loss: 0.67523 | Acc: 71.591\n",
      "Epoch 019: | Loss: 0.66889 | Acc: 71.825\n",
      "Epoch 020: | Loss: 0.66310 | Acc: 72.161\n",
      "Epoch 021: | Loss: 0.65745 | Acc: 72.427\n",
      "Epoch 022: | Loss: 0.65151 | Acc: 72.799\n",
      "Epoch 023: | Loss: 0.64737 | Acc: 72.997\n",
      "Epoch 024: | Loss: 0.64228 | Acc: 73.146\n",
      "Epoch 025: | Loss: 0.63782 | Acc: 73.400\n",
      "Epoch 026: | Loss: 0.63328 | Acc: 73.663\n",
      "Epoch 027: | Loss: 0.62768 | Acc: 73.875\n",
      "Epoch 028: | Loss: 0.62589 | Acc: 74.035\n",
      "Epoch 029: | Loss: 0.62183 | Acc: 74.243\n",
      "Epoch 030: | Loss: 0.61579 | Acc: 74.468\n",
      "Epoch 031: | Loss: 0.61155 | Acc: 74.739\n",
      "Epoch 032: | Loss: 0.60932 | Acc: 74.796\n",
      "Epoch 033: | Loss: 0.60549 | Acc: 75.019\n",
      "Epoch 034: | Loss: 0.60378 | Acc: 75.052\n",
      "Epoch 035: | Loss: 0.60098 | Acc: 75.250\n",
      "Epoch 036: | Loss: 0.59713 | Acc: 75.217\n",
      "Epoch 037: | Loss: 0.59433 | Acc: 75.460\n",
      "Epoch 038: | Loss: 0.58976 | Acc: 75.642\n",
      "Epoch 039: | Loss: 0.58772 | Acc: 75.767\n",
      "Epoch 040: | Loss: 0.58420 | Acc: 76.007\n",
      "Epoch 041: | Loss: 0.58042 | Acc: 76.040\n",
      "Epoch 042: | Loss: 0.57987 | Acc: 76.147\n",
      "Epoch 043: | Loss: 0.57679 | Acc: 76.308\n",
      "Epoch 044: | Loss: 0.57488 | Acc: 76.290\n",
      "Epoch 045: | Loss: 0.57005 | Acc: 76.612\n",
      "Epoch 046: | Loss: 0.56813 | Acc: 76.662\n",
      "Epoch 047: | Loss: 0.56902 | Acc: 76.677\n",
      "Epoch 048: | Loss: 0.56461 | Acc: 76.789\n",
      "Epoch 049: | Loss: 0.56170 | Acc: 77.024\n",
      "Epoch 050: | Loss: 0.56064 | Acc: 77.014\n",
      "Epoch 051: | Loss: 0.55872 | Acc: 77.148\n",
      "Epoch 052: | Loss: 0.55630 | Acc: 77.137\n",
      "Epoch 053: | Loss: 0.55580 | Acc: 77.317\n",
      "Epoch 054: | Loss: 0.55231 | Acc: 77.439\n",
      "Epoch 055: | Loss: 0.55088 | Acc: 77.516\n",
      "Epoch 056: | Loss: 0.54795 | Acc: 77.626\n",
      "Epoch 057: | Loss: 0.54627 | Acc: 77.739\n",
      "Epoch 058: | Loss: 0.54487 | Acc: 77.800\n",
      "Epoch 059: | Loss: 0.54224 | Acc: 77.866\n",
      "Epoch 060: | Loss: 0.54276 | Acc: 77.838\n",
      "Epoch 061: | Loss: 0.53925 | Acc: 78.082\n",
      "Epoch 062: | Loss: 0.53904 | Acc: 78.014\n",
      "Epoch 063: | Loss: 0.53401 | Acc: 78.223\n",
      "Epoch 064: | Loss: 0.53403 | Acc: 78.257\n",
      "Epoch 065: | Loss: 0.53371 | Acc: 78.263\n",
      "Epoch 066: | Loss: 0.53195 | Acc: 78.272\n",
      "Epoch 067: | Loss: 0.52904 | Acc: 78.425\n",
      "Epoch 068: | Loss: 0.52977 | Acc: 78.388\n",
      "Epoch 069: | Loss: 0.53012 | Acc: 78.323\n",
      "Epoch 070: | Loss: 0.52463 | Acc: 78.707\n",
      "Epoch 071: | Loss: 0.52668 | Acc: 78.537\n",
      "Epoch 072: | Loss: 0.52308 | Acc: 78.681\n",
      "Epoch 073: | Loss: 0.52253 | Acc: 78.739\n",
      "Epoch 074: | Loss: 0.51869 | Acc: 78.921\n",
      "Epoch 075: | Loss: 0.51956 | Acc: 78.861\n",
      "Epoch 076: | Loss: 0.51936 | Acc: 78.896\n",
      "Epoch 077: | Loss: 0.51554 | Acc: 79.059\n",
      "Epoch 078: | Loss: 0.51546 | Acc: 79.102\n",
      "Epoch 079: | Loss: 0.51374 | Acc: 79.186\n",
      "Epoch 080: | Loss: 0.51427 | Acc: 79.210\n",
      "Epoch 081: | Loss: 0.51180 | Acc: 79.234\n",
      "Epoch 082: | Loss: 0.50894 | Acc: 79.388\n",
      "Epoch 083: | Loss: 0.50955 | Acc: 79.352\n",
      "Epoch 084: | Loss: 0.50889 | Acc: 79.410\n",
      "Epoch 085: | Loss: 0.50590 | Acc: 79.572\n",
      "Epoch 086: | Loss: 0.50508 | Acc: 79.623\n",
      "Epoch 087: | Loss: 0.50309 | Acc: 79.659\n",
      "Epoch 088: | Loss: 0.50271 | Acc: 79.645\n",
      "Epoch 089: | Loss: 0.50091 | Acc: 79.829\n",
      "Epoch 090: | Loss: 0.49891 | Acc: 79.856\n",
      "Epoch 091: | Loss: 0.50053 | Acc: 79.832\n",
      "Epoch 092: | Loss: 0.49985 | Acc: 79.796\n",
      "Epoch 093: | Loss: 0.49919 | Acc: 79.853\n",
      "Epoch 094: | Loss: 0.49757 | Acc: 79.870\n",
      "Epoch 095: | Loss: 0.49481 | Acc: 80.024\n",
      "Epoch 096: | Loss: 0.49288 | Acc: 80.033\n",
      "Epoch 097: | Loss: 0.49335 | Acc: 80.058\n",
      "Epoch 098: | Loss: 0.49105 | Acc: 80.138\n",
      "Epoch 099: | Loss: 0.49011 | Acc: 80.081\n",
      "Epoch 100: | Loss: 0.49301 | Acc: 80.119\n"
     ]
    }
   ],
   "source": [
    "train_model_ternary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 57.0\n"
     ]
    }
   ],
   "source": [
    "test_model_ternary(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_ternary['concat_input_features_2']\n",
    "y = df_ternary['class']\n",
    "\n",
    "# Split the dataset into 80% training dataset and 20% testing dataset\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train data\n",
    "train_data = trainData(torch.FloatTensor(x_train.tolist()), \n",
    "                       torch.FloatTensor(y_train))\n",
    "## test data    \n",
    "test_data = testData(torch.FloatTensor(x_test.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Loss: 0.90813 | Acc: 59.358\n",
      "Epoch 002: | Loss: 0.84278 | Acc: 62.880\n",
      "Epoch 003: | Loss: 0.82552 | Acc: 63.622\n",
      "Epoch 004: | Loss: 0.81350 | Acc: 64.262\n",
      "Epoch 005: | Loss: 0.80305 | Acc: 64.778\n",
      "Epoch 006: | Loss: 0.79276 | Acc: 65.254\n",
      "Epoch 007: | Loss: 0.78232 | Acc: 65.812\n",
      "Epoch 008: | Loss: 0.77178 | Acc: 66.382\n",
      "Epoch 009: | Loss: 0.76321 | Acc: 66.742\n",
      "Epoch 010: | Loss: 0.75476 | Acc: 67.319\n",
      "Epoch 011: | Loss: 0.74597 | Acc: 67.665\n",
      "Epoch 012: | Loss: 0.73657 | Acc: 68.159\n",
      "Epoch 013: | Loss: 0.72833 | Acc: 68.512\n",
      "Epoch 014: | Loss: 0.72178 | Acc: 68.912\n",
      "Epoch 015: | Loss: 0.71326 | Acc: 69.347\n",
      "Epoch 016: | Loss: 0.70599 | Acc: 69.620\n",
      "Epoch 017: | Loss: 0.69941 | Acc: 70.033\n",
      "Epoch 018: | Loss: 0.69192 | Acc: 70.278\n",
      "Epoch 019: | Loss: 0.68419 | Acc: 70.690\n",
      "Epoch 020: | Loss: 0.67823 | Acc: 71.061\n",
      "Epoch 021: | Loss: 0.67399 | Acc: 71.223\n",
      "Epoch 022: | Loss: 0.66797 | Acc: 71.364\n",
      "Epoch 023: | Loss: 0.66216 | Acc: 71.787\n",
      "Epoch 024: | Loss: 0.65866 | Acc: 71.964\n",
      "Epoch 025: | Loss: 0.65156 | Acc: 72.379\n",
      "Epoch 026: | Loss: 0.64853 | Acc: 72.467\n",
      "Epoch 027: | Loss: 0.64281 | Acc: 72.623\n",
      "Epoch 028: | Loss: 0.63850 | Acc: 72.835\n",
      "Epoch 029: | Loss: 0.63807 | Acc: 72.868\n",
      "Epoch 030: | Loss: 0.63089 | Acc: 73.273\n",
      "Epoch 031: | Loss: 0.62798 | Acc: 73.379\n",
      "Epoch 032: | Loss: 0.62395 | Acc: 73.424\n",
      "Epoch 033: | Loss: 0.62227 | Acc: 73.554\n",
      "Epoch 034: | Loss: 0.61642 | Acc: 73.916\n",
      "Epoch 035: | Loss: 0.61378 | Acc: 73.963\n",
      "Epoch 036: | Loss: 0.61180 | Acc: 74.090\n",
      "Epoch 037: | Loss: 0.60802 | Acc: 74.188\n",
      "Epoch 038: | Loss: 0.60427 | Acc: 74.467\n",
      "Epoch 039: | Loss: 0.60194 | Acc: 74.472\n",
      "Epoch 040: | Loss: 0.59804 | Acc: 74.652\n",
      "Epoch 041: | Loss: 0.59637 | Acc: 74.876\n",
      "Epoch 042: | Loss: 0.59132 | Acc: 75.026\n",
      "Epoch 043: | Loss: 0.58989 | Acc: 75.079\n",
      "Epoch 044: | Loss: 0.58785 | Acc: 75.195\n",
      "Epoch 045: | Loss: 0.58617 | Acc: 75.153\n",
      "Epoch 046: | Loss: 0.58237 | Acc: 75.389\n",
      "Epoch 047: | Loss: 0.57918 | Acc: 75.473\n",
      "Epoch 048: | Loss: 0.57743 | Acc: 75.582\n",
      "Epoch 049: | Loss: 0.57674 | Acc: 75.671\n",
      "Epoch 050: | Loss: 0.57433 | Acc: 75.673\n",
      "Epoch 051: | Loss: 0.57177 | Acc: 75.849\n",
      "Epoch 052: | Loss: 0.56950 | Acc: 76.007\n",
      "Epoch 053: | Loss: 0.56736 | Acc: 75.990\n",
      "Epoch 054: | Loss: 0.56798 | Acc: 76.041\n",
      "Epoch 055: | Loss: 0.56377 | Acc: 76.275\n",
      "Epoch 056: | Loss: 0.56241 | Acc: 76.281\n",
      "Epoch 057: | Loss: 0.55912 | Acc: 76.452\n",
      "Epoch 058: | Loss: 0.55898 | Acc: 76.465\n",
      "Epoch 059: | Loss: 0.55742 | Acc: 76.492\n",
      "Epoch 060: | Loss: 0.55659 | Acc: 76.529\n",
      "Epoch 061: | Loss: 0.55401 | Acc: 76.680\n",
      "Epoch 062: | Loss: 0.55334 | Acc: 76.715\n",
      "Epoch 063: | Loss: 0.54936 | Acc: 76.879\n",
      "Epoch 064: | Loss: 0.54824 | Acc: 76.985\n",
      "Epoch 065: | Loss: 0.54806 | Acc: 76.932\n",
      "Epoch 066: | Loss: 0.54471 | Acc: 77.099\n",
      "Epoch 067: | Loss: 0.54541 | Acc: 77.037\n",
      "Epoch 068: | Loss: 0.54278 | Acc: 77.109\n",
      "Epoch 069: | Loss: 0.54018 | Acc: 77.318\n",
      "Epoch 070: | Loss: 0.54088 | Acc: 77.314\n",
      "Epoch 071: | Loss: 0.53776 | Acc: 77.374\n",
      "Epoch 072: | Loss: 0.53525 | Acc: 77.538\n",
      "Epoch 073: | Loss: 0.53533 | Acc: 77.542\n",
      "Epoch 074: | Loss: 0.53461 | Acc: 77.618\n",
      "Epoch 075: | Loss: 0.53288 | Acc: 77.670\n",
      "Epoch 076: | Loss: 0.53306 | Acc: 77.633\n",
      "Epoch 077: | Loss: 0.53029 | Acc: 77.811\n",
      "Epoch 078: | Loss: 0.52832 | Acc: 77.823\n",
      "Epoch 079: | Loss: 0.52611 | Acc: 77.954\n",
      "Epoch 080: | Loss: 0.52590 | Acc: 78.003\n",
      "Epoch 081: | Loss: 0.52463 | Acc: 77.964\n",
      "Epoch 082: | Loss: 0.52400 | Acc: 78.034\n",
      "Epoch 083: | Loss: 0.52396 | Acc: 78.005\n",
      "Epoch 084: | Loss: 0.52227 | Acc: 78.138\n",
      "Epoch 085: | Loss: 0.52036 | Acc: 78.137\n",
      "Epoch 086: | Loss: 0.51909 | Acc: 78.262\n",
      "Epoch 087: | Loss: 0.51850 | Acc: 78.376\n",
      "Epoch 088: | Loss: 0.51968 | Acc: 78.184\n",
      "Epoch 089: | Loss: 0.51669 | Acc: 78.319\n",
      "Epoch 090: | Loss: 0.51599 | Acc: 78.419\n",
      "Epoch 091: | Loss: 0.51438 | Acc: 78.424\n",
      "Epoch 092: | Loss: 0.51439 | Acc: 78.459\n",
      "Epoch 093: | Loss: 0.51389 | Acc: 78.460\n",
      "Epoch 094: | Loss: 0.51253 | Acc: 78.600\n",
      "Epoch 095: | Loss: 0.51093 | Acc: 78.607\n",
      "Epoch 096: | Loss: 0.51090 | Acc: 78.544\n",
      "Epoch 097: | Loss: 0.50919 | Acc: 78.671\n",
      "Epoch 098: | Loss: 0.51058 | Acc: 78.664\n",
      "Epoch 099: | Loss: 0.50687 | Acc: 78.781\n",
      "Epoch 100: | Loss: 0.50572 | Acc: 78.916\n"
     ]
    }
   ],
   "source": [
    "train_model_ternary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 59.0\n"
     ]
    }
   ],
   "source": [
    "test_model_ternary(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comments about this question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Word2Vec Model</th>\n",
       "      <th>Classification Type</th>\n",
       "      <th>Input Features Type</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FNN</td>\n",
       "      <td>Google News</td>\n",
       "      <td>Binary</td>\n",
       "      <td>Concat_first_10</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FNN</td>\n",
       "      <td>Amazon Reviews(Our)</td>\n",
       "      <td>Binary</td>\n",
       "      <td>Concat_first_10</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FNN</td>\n",
       "      <td>Google News</td>\n",
       "      <td>Ternary</td>\n",
       "      <td>Concat_first_10</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FNN</td>\n",
       "      <td>Amazon Reviews(Our)</td>\n",
       "      <td>Ternary</td>\n",
       "      <td>Concat_first_10</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model       Word2Vec Model Classification Type Input Features Type Accuracy\n",
       "0   FNN          Google News              Binary     Concat_first_10     0.73\n",
       "1   FNN  Amazon Reviews(Our)              Binary     Concat_first_10     0.75\n",
       "2   FNN          Google News             Ternary     Concat_first_10     0.57\n",
       "3   FNN  Amazon Reviews(Our)             Ternary     Concat_first_10     0.59"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'Model': ['FNN', 'FNN', 'FNN', 'FNN'], \n",
    "     'Word2Vec Model': ['Google News', 'Amazon Reviews(Our)', 'Google News', 'Amazon Reviews(Our)'],\n",
    "     'Classification Type': ['Binary', 'Binary', 'Ternary', 'Ternary',],\n",
    "     'Input Features Type': ['Concat_first_10' , 'Concat_first_10', 'Concat_first_10', 'Concat_first_10'],\n",
    "     'Accuracy': ['0.73', '0.75', '0.57', '0.59']}\n",
    "\n",
    "df_results_part_4_b = pd.DataFrame(data=d)\n",
    "df_results_part_4_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Word2Vec Features/Other Features</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>Google News</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>Google News</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>Amazon Reviews(Our)</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>Amazon Reviews(Our)</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Model Word2Vec Features/Other Features Accuracy\n",
       "0  Perceptron                      Google News     0.71\n",
       "1         SVM                      Google News     0.82\n",
       "2  Perceptron              Amazon Reviews(Our)     0.81\n",
       "3         SVM              Amazon Reviews(Our)     0.85\n",
       "4  Perceptron                           TF-IDF     0.85\n",
       "5         SVM                           TF-IDF     0.81"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_part_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Word2Vec Model</th>\n",
       "      <th>Classification Type</th>\n",
       "      <th>Input Features Type</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FNN</td>\n",
       "      <td>Google News</td>\n",
       "      <td>Binary</td>\n",
       "      <td>Average</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FNN</td>\n",
       "      <td>Amazon Reviews(Our)</td>\n",
       "      <td>Binary</td>\n",
       "      <td>Average</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FNN</td>\n",
       "      <td>Google News</td>\n",
       "      <td>Ternary</td>\n",
       "      <td>Average</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FNN</td>\n",
       "      <td>Amazon Reviews(Our)</td>\n",
       "      <td>Ternary</td>\n",
       "      <td>Average</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model       Word2Vec Model Classification Type Input Features Type Accuracy\n",
       "0   FNN          Google News              Binary             Average     0.85\n",
       "1   FNN  Amazon Reviews(Our)              Binary             Average     0.87\n",
       "2   FNN          Google News             Ternary             Average     0.68\n",
       "3   FNN  Amazon Reviews(Our)             Ternary             Average     0.71"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_part_4_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Word2Vec Model</th>\n",
       "      <th>Classification Type</th>\n",
       "      <th>Input Features Type</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FNN</td>\n",
       "      <td>Google News</td>\n",
       "      <td>Binary</td>\n",
       "      <td>Concat_first_10</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FNN</td>\n",
       "      <td>Amazon Reviews(Our)</td>\n",
       "      <td>Binary</td>\n",
       "      <td>Concat_first_10</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FNN</td>\n",
       "      <td>Google News</td>\n",
       "      <td>Ternary</td>\n",
       "      <td>Concat_first_10</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FNN</td>\n",
       "      <td>Amazon Reviews(Our)</td>\n",
       "      <td>Ternary</td>\n",
       "      <td>Concat_first_10</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model       Word2Vec Model Classification Type Input Features Type Accuracy\n",
       "0   FNN          Google News              Binary     Concat_first_10     0.73\n",
       "1   FNN  Amazon Reviews(Our)              Binary     Concat_first_10     0.75\n",
       "2   FNN          Google News             Ternary     Concat_first_10     0.57\n",
       "3   FNN  Amazon Reviews(Our)             Ternary     Concat_first_10     0.59"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_part_4_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen from the above tables that for binary classification(as mentioned in the question pdf note), the FNN model(input features - Average Word2Vec vectors) works better or comparable(in some cases) than both the Perceptron and the SVM model for Google News/Amazon Reviews(Our)/TF-IDF Word2Vec features. However the FNN model(input features - Concat(first 10) vectors) performs poorly than both the Perceptron and the SVM model for Google News/Amaxon Reviews(Our)/TF-IDF Word2Vec features.\n",
    "This shows that the average vectors is a better input feature type selection here than concatenating the first 10 vectors. Also the feedforward MLP model is stronger and slightly more accurate here at binary classification if average vectors are considered. This is so since we get a lot of hyperparameter and design paramter tuning flexibility in Neural Network models(epochs,batch_size,learning_rate,activation functions(linear/non-linear:relu),loss,optimizer,etc.) that can help us achieve possibly a higher accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
